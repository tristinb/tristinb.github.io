{
	"version": "https://jsonfeed.org/version/1.1",
	"title": "Processing Beliefs",
	"language": "en",
	"home_page_url": "https://tristinb.github.io/",
	"feed_url": "https://tristinb.github.io/feed/feed.json",
	"description": "I am writing about beliefs, bro.",
	"author": {
		"name": "Tristin Beckman",
		"url": "https://tristinb.github.io/about"
	},
	"items": [
		{
			"id": "https://tristinb.github.io/blog/rafah_gaza_war/",
			"url": "https://tristinb.github.io/blog/rafah_gaza_war/",
			"title": "Can Biden Make Bibi Balk?",
			"content_html": "<p>In the ongoing Israel-Gaza war, Biden recently told the press that he would cut off certain types of military aid to Israel if Netanyahu invaded Rafah. Netanyahu and his most hawkish advisors responded that Israel will do what it deems necessary to defend itself. This post applies a simple model to the current situation to better understand Biden's options and the dynamics in the dispute between Biden and Netanyahu.</p>\n<h2 id=\"model\" tabindex=\"-1\">Model <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/rafah_gaza_war/\">#</a></h2>\n<p>We can model Israel's decision to invade Rafah as a Bayesian game. A key feature of Bayesian games is that a player can be a certain &quot;type&quot;. For example, they can be sane or crazy, red or green, strong or weak, any number between 0 and 100 etc. In the model, players don't know the others' types, but they do know the probability distribution over the type. In this setup, we have two players: Biden (B) and Netanyahu (N). Biden's type is either strong or weak. Biden knows his type, but Netanyahu only knows the probability that Biden is either strong or weak.</p>\n<p>Netanyahu can choose to either <code>Attack</code> or <code>Refrain</code>. If he chooses <code>Refrain</code>, the game ends, leaving Biden a payoff for convincing Netanyahu to refrain, $RB$, and Netanyahu a payoff for refraining, $RN$.</p>\n<p>If Netanyahu chooses to attack, he will get a payoff of $K$. But if Biden chooses to Sanction Netanyahu, or to cut off military aid, that $K$ will come at a cost. Since that cost can be seen as coming from the US government, we assume it is the same regardless of Biden's type. If Biden chooses <code>Backdown</code> Israel won't pay a cost from the US reaction, so Netanyahu gets all of $K$ and Biden gets a payoff of $Bd$.</p>\n<p>The game is shown in the figure below. The left side of the tree represents the world where Biden is strong; the right side represents where Biden is weak. The dashed line means that Netanyahu, N, does not know whether he is in the world of Strong or Weak Biden.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/2Y5T0McLcY-423.avif 423w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/2Y5T0McLcY-423.webp 423w\"><img alt=\"Game Tree\" loading=\"lazy\" decoding=\"async\" src=\"https://tristinb.github.io/img/2Y5T0McLcY-423.png\" width=\"423\" height=\"311\"></picture></p>\n<p>You can see that the game has many undefined variables, or parameters. If they take on certain values, we can find a unique solution to the game. Here are the parameters we need to define:</p>\n<table>\n<thead>\n<th>Parameter</th><th>Description</th>\n</thead>\n<tr><td>$\\theta$</td><td>Probability Biden's type is Strong</td></tr>\n<tr><td>$RB$</td><td>B's payoff for N refraining </td></tr>\n<tr><td>$RN$</td><td>N's payoff for refraining </td></tr>\n<tr><td>$K$</td><td>N's payoff for attacking</td></tr>\n<tr><td>cost</td><td>Cost from B's retaliation</td></tr>\n<tr><td>$S_s$</td><td>Payoff to strong type for sanctioning</td></tr>\n<tr><td>$S_w$</td><td>Payoff to weak type for sanctioning</td></tr>\n<tr><td>$Bd$</td><td>Payoff for backing down</td></tr>\n</table>\n<p>To find the subgame perfect Bayesian Nash equilibrium, we can start from the bottom of the tree and work our way up. First, let's start on the left, where Biden is the strong type. Since Strong Biden loves to fight, it is safe to assume his payoff for <code>Sanction</code> is larger than that for <code>Backdown</code>. Concretely, since ${S_s}$ is greater than $Bd$ strong Biden chooses <code>Sanction</code>. Furthermore, strong Biden seeks to impose a large cost on Israel for attacking, let's assume that $RN$ is greater than $K-{cost}$. In this case, Netanyahu gets a higher payoff, and therefore chooses, <code>Refrain</code>. Putting this together, under Strong Biden we get <code>Refrain</code> as an equilibrium as long as Biden's payoff for <code>Sanction</code> is greater than the payoff for <code>Backdown</code> and $K-{cost}$ is less than the payoff for <code>Refrain</code>. If either of these fail to hold, and we will revisit the second assumption later, we will get an equilibrium where Netanyahu attacks.</p>\n<p>We can repeat this on the right hand side of the tree. Here, Weak Biden does not like conflict. Therefore, if Netanyahu attacks, Biden gets a higher payoff for <code>Backdown</code> than for <code>Sanction</code>. In the model this is expressed as $Bd$ being greater than ${S_w}$. Since Weak Biden will back down, Netanyahu will attacks and can expect a payoff of $K$. This is a reasonable assumption since if $K$ wasn't credibly better than refraining, Netanyahu wouldn't have threatened to attack in the first place. Putting this together, under Weak Biden we get an equilibrium where Netanyahu chooses <code>Attack</code> and Biden chooses <code>Backdown</code>. This is different than the equilibrium under Strong Biden. The table below shows the payoffs and Netanyahu's decisions under Biden's two types.</p>\n<table>\n<tr><th>Strong</th><th>Weak</th><th>Payoff Strong</th><th>Payoff Weak</th></tr>\n<tr><td>Refrain</td><td>Attack</td><td>$\\theta \\times {RN}$</td><td>$(1-\\theta) \\times K$</td></tr>\n</table>\n<p>For a subgame perfect Bayesian Nash equilibrium to hold, Netanyahu will choose to <code>Refrain</code> if the expected payoff for restraining is greater than the expected payoff for attacking. In the model this is expressed as $\\theta \\times {RN} \\geq (1-\\theta)K$. Much of this depends on $\\theta$, or Netanyahu's beliefs over Biden's type. Focusing on $\\theta$, we can simplify this expression to $\\theta \\leq \\frac{K}{({RN}+K)}$. This equation shows that as $K$ -- or the payoff Netanyahu gets from invading increases -- he needs to be even more convinced Biden is the strong type in order to refrain from attacking. Conversely, as $RN$, or the payoff he gets for refraining, increases he needs to be even less convinced Biden is of the strong type in order to refrain.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/rafah_gaza_war/\" id=\"fnref1\">[1]</a></sup></p>\n<p>In order to convince Netanyahu to refrain, and avoid an invasion of Rafah, the model suggests three things Biden could do.</p>\n<p>First, Biden could increase $RN$, which is Netenyahu's payoff for refraining. He could do this, for example, by offering more security guarantees or support in the United Nations. <a href=\"https://www.axios.com/2024/04/29/netanyahu-biden-icc-arrest-warrants-war-crimes\">Protection from ICC prosecution</a> could be another way to get Netanyahu to refrain.</p>\n<p>Second, Biden could try to convince Netanyahu that he is the strong type and that he will not back down from his threats. Biden going public with these threats suggests that private pressure have failed since going public will make it harder to choose <code>Backdown</code> because his domestic audiences will find him weak. A large literature on <a href=\"https://en.wikipedia.org/wiki/Audience_cost\">Audience Costs</a> explores these dynamics in detail.</p>\n<p>Third, Biden could further escalate his threats. This would decrease the payoff Netanyahu gets by invading in the event that Biden is the strong type. In other words, Netanyahu can be relatively convinced Biden is the weak type, but still choose to refrain since the cost in the event Biden is the strong type are so large.</p>\n<p>Finally, we can revisit the assumption that strong Biden can impose sufficiently strong sanctions to make Netanyahu's payoff for refraining greater than attacking. If strong Biden cannot credibly impose high enough costs to Netanyahu in the event that he attacks, for instance because he faces too many domestic constraints, then there is no equilibrium where Netanyahu chooses to refrain.</p>\n<p>If you are interested in further exploring the three scenarios by manipulating $K$ and $RN$, you can click the button below.</p>\n<p><button id=\"toggle-button\" onclick=\"toggleInteraction()\">Explore Scenarios</button></p>\n<div id=\"code\">\n<p>By changing the values of $K$, the payoff Netanyahu gets from attacking, and $RN$, the value he gets from refraining, you can see what minimum belief Netanyahu must have over Biden being the strong type in order to refrain according to the model.</p>\n<table>\n<tr><th>Parameter</th><th>Value</th></tr>\n<tr><td>$K$</td><td><input type=\"number\" id=\"k\" min=\"0\" max=\"10\" value=\"5\" step=\"0.5\" style=\"width: 100%;\" onchange=\"calculateMinProb()\"></td></tr>\n<tr><td>$RN$</td><td><input type=\"number\" id=\"rn\" min=\"0\" max=\"10\" value=\"5\" step=\"0.5\" style=\"width: 100%;\" onchange=\"calculateMinProb()\"></td></tr>\n<tr style=\"font-weight: bold;\"><td>$\\theta$</td><td id=\"theta\">0.5</td>\n</tr></table>\n<p>By increasing $K$, or the value Netanyahu gets from attacking, $\\theta$ will rise. This means that Netanyahu can be more certain that Biden is the strong type, yet still choose to attack since he gets such a high payoff for doing so. Conversely, increasing $RN$ will decrease $\\theta$. This means that as the payoffs to refraining rise, Netanyahu can be more certain Biden is the weak type, yet still refrain.</p>\n</div>\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/rafah_gaza_war/\">#</a></h2>\n<script>\n\nfunction toggleInteraction() {\n    var code = document.getElementById(\"code\");\n    var button = document.getElementById(\"toggle-button\");\n    code.classList.toggle('active');\n\n    var isVisible = code.classList.contains('active');\n    var buttonText = isVisible ? 'Hide' : 'Explore Scenarios';\n    button.textContent = buttonText\n}\n\nconst calculateMinProb = () => {\n    const k = parseFloat(document.getElementById(\"k\").value);\n    const rn = parseFloat(document.getElementById(\"rn\").value);\n    const theta =  k / (k + rn);\n    document.getElementById(\"theta\").textContent = parseFloat(theta.toFixed(4))\n}\n</script><hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>Formally if you take first derivatives you can see that the expression is increasing in $K$ and decreasing in $RN$. As both of the second derivatives are negative, as $K$ gets larger $\\theta$ approaches 1; and as $RN$ gets smaller, $\\theta$ approaches 0. <a href=\"https://tristinb.github.io/blog/rafah_gaza_war/\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2024-05-09T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/polls/",
			"url": "https://tristinb.github.io/blog/polls/",
			"title": "Sources of Polling Error",
			"content_html": "<p>Pollsters and journalists often present polling results as being correct to within a plus or minus three percentage points, with 95 percent confidence. However, we often see election results fall outside this three percentage point error. In the 2020 election, for example, polls missed by an average of <a href=\"https://aapor.org/wp-content/uploads/2022/11/Task-Force-on-2020-Pre-Election-Polling_Executive-Summary.pdf\">4.5 percentage points at the national level</a>. This post explores where this additional polling error comes from and how we should interpret polls in light of this additional error. As a quick note, since polls are surveys of respondents' vote preferences, I use the words polls and surveys synonymously.</p>\n<h2 id=\"sampling-error-the-plus-or-minus-3-percent\" tabindex=\"-1\">Sampling Error: The Plus or Minus 3 Percent <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<p>If we assume a three percent margin of error and we see a poll that says 54 percent of the respondents prefer Hans to Franz then we can be 95 percent confident that the true proportion of the population as a whole that prefers Hans lies somewhere between 51 and 57 percent. The &quot;95 percent confident&quot; means that if we ran our poll a million times, we would only see a result less than 51 percent or greater than 57 in only 5 percent of these polls.</p>\n<p>The following bit of python code simulates this process. The code assumes you ask 1,000 people if they prefer Hans or Franz. If they prefer Hans, record a 1. Otherwise, record 0. We assume the true proportion of the population that prefers Hans a is 54 percent. This is one poll. We can now run this 10 thousand times and see how often the polls find support as either less than 51 percent or greater than 57 percent.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\npopulation_pct<span class=\"token operator\">=</span><span class=\"token number\">.54</span> <span class=\"token comment\"># True value of the population</span>\npoll_sample_size <span class=\"token operator\">=</span> <span class=\"token number\">1000</span> <span class=\"token comment\"># poll 1000 people</span>\ntest_draws <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>binomial<span class=\"token punctuation\">(</span>poll_sample_size<span class=\"token punctuation\">,</span> pop_pct<span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token number\">10_000</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span>poll_sample_size <span class=\"token comment\"># sample from a binomial distribution; divide by n since we want a proportion</span></code></pre>\n<p>The plot below compares each of the 10 thousand samples from this distribution to what we would expect in theory. Notice that they are quite similar.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">from</span> scipy <span class=\"token keyword\">import</span> stats\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\nmin_num_vot <span class=\"token operator\">=</span> <span class=\"token number\">450</span>\nmax_num_vote <span class=\"token operator\">=</span> <span class=\"token number\">631</span>\n\nx <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>min_num_vot<span class=\"token punctuation\">,</span> max_num_vote<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\ntheoretical_distribution <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>n<span class=\"token operator\">=</span>poll_sample_size<span class=\"token punctuation\">,</span> p<span class=\"token operator\">=</span>pop_pct<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>pmf<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx_label <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>i<span class=\"token operator\">/</span>poll_sample_size <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> x<span class=\"token punctuation\">]</span> <span class=\"token comment\"># scale for plot, want a proportion, not raw count out of 1000</span>\n\nfig<span class=\"token punctuation\">,</span> ax <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplots<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nhist<span class=\"token punctuation\">,</span> bins<span class=\"token punctuation\">,</span> _ <span class=\"token operator\">=</span> ax<span class=\"token punctuation\">.</span>hist<span class=\"token punctuation\">(</span>test_draws<span class=\"token punctuation\">,</span> density<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Samples'</span><span class=\"token punctuation\">,</span> bins<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># scale pmf to match area in histogram; bin widths are scaled by 1000</span>\nscaled_pmf <span class=\"token operator\">=</span> theoretical_dist<span class=\"token operator\">*</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>hist<span class=\"token operator\">*</span>np<span class=\"token punctuation\">.</span>diff<span class=\"token punctuation\">(</span>bins<span class=\"token punctuation\">)</span><span class=\"token operator\">*</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_label<span class=\"token punctuation\">,</span> scaled_pmf<span class=\"token punctuation\">,</span> linestyle<span class=\"token operator\">=</span><span class=\"token string\">'--'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'True Distribution'</span><span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'Samples vs True Distribution'</span><span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>set_ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Number of Polls'</span><span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nprop_outside_3_pct <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">abs</span><span class=\"token punctuation\">(</span>test_draws<span class=\"token operator\">-</span>population_pct<span class=\"token punctuation\">)</span><span class=\"token operator\">></span><span class=\"token number\">.03</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>test_draws<span class=\"token punctuation\">)</span> <span class=\"token comment\"># how many are outside 3%?</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'Proportion outside 3 percentage points: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>prop_outside_3_pct<span class=\"token punctuation\">:</span><span class=\"token format-spec\"> .2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span></code></pre>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/TZDWyr7ZpS-640.avif 640w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/TZDWyr7ZpS-640.webp 640w\"><img alt=\"Samples drawn from the above distribution\" loading=\"lazy\" decoding=\"async\" src=\"https://tristinb.github.io/img/TZDWyr7ZpS-640.png\" width=\"640\" height=\"480\"></picture></p>\n<pre class=\"language-text\" tabindex=\"0\"><code class=\"language-text\">Proportion outside 3 percentage points:  0.057</code></pre>\n<p>The output shows that close to five percent of the estimates fell outside of plus or minus three percentage points of 54 percent, or about 95 percent were between 51 and 57 percent support for Hans. We see 5.7 percent, rather than 5 percent, of the estimate fell outside of 3 percent because the estimate's standard error, depends on both the number of people you poll (n) and the true proportion of the population that supports candidate A.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/polls/\" id=\"fnref1\">[1]</a></sup> But a sample size of 1000 generally gets close to 3 percent margins at 95 percent confidence.</p>\n<p>The three percentage point error above occurs because we only take a sample of 1,000 from the population rather than measuring the whole thing. Randomness in who is sampled leads to deviations from the population's true value. However, sources other than sampling error generally cause polls and surveys to be off.</p>\n<h2 id=\"bias-who-answers-pollsters\" tabindex=\"-1\">Bias: Who Answers Pollsters? <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<p>In addition to sampling error, any error in a poll can be decomposed to two factors: bias and variance. Bias is how systematically wrong polls tend to be in a certain direction. For example, when polls all tend to overestimate their support for Franz, they are biased. Variance is the error in excess of the sampling error described above, but is not associated with any particular direction -- it can be either to favorable or too unfavorable to Franz. Typically, tools to reduce bias increase variance and vice-versa, this is the well-known <a href=\"https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff\">bias-variance tradeoff</a>.</p>\n<p>A poll will be biased if one candidate's supporters are systematically less likely to respond to a pollster than their competitor's supporters. Conversely, sometimes a candidate's supporters may over-respond to polls relative to others. For example, they could be particularly excited about their candidate, or be eager to voice their displeasure at a scandal.</p>\n<p>The simulation below shows what happens when one side's supporters are systematically less likely to respond to the pollster. We can then look at a simple method to adjust this bias assuming we have estimates on what group is under-responding.</p>\n<p>For the simulation, assume the population is split in half between two groups: group A and group B. Group A will support Hans with a 44 percent probability, while group B will support Hans with a 64 percent probability. If both groups were equally likely to respond, we would expect to see an average of 54 percent support for Hans. However, let's assume group B will only respond to the pollster with a 25 percent probability; while everybody in group A responds to the pollster. In the simulation below, the pollster just needs to sample 1000 people. The pollster doesn't necessarily know what group each respondent belongs to, even though we will collect the groups in the code.</p>\n<p>The code below simulates one pollster collecting this data.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\">a_vote_prob <span class=\"token operator\">=</span> <span class=\"token number\">.44</span>\nb_vote_prob <span class=\"token operator\">=</span> <span class=\"token number\">.64</span>\nb_response_prob <span class=\"token operator\">=</span> <span class=\"token number\">.25</span>\nresults <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\ngroup <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\npoll_sample_size <span class=\"token operator\">=</span> <span class=\"token number\">1000</span>\ni <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n<span class=\"token keyword\">while</span> i<span class=\"token operator\">&lt;</span>poll_sample_size<span class=\"token punctuation\">:</span>\n    a_vote <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>bernoulli<span class=\"token punctuation\">(</span>a_vote_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    results<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>a_vote<span class=\"token punctuation\">)</span>\n    group<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token string\">'a'</span><span class=\"token punctuation\">)</span>\n    i<span class=\"token operator\">+=</span><span class=\"token number\">1</span>\n    <span class=\"token keyword\">if</span> i<span class=\"token operator\">==</span>poll_sample_size<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">break</span>\n    <span class=\"token keyword\">if</span> stats<span class=\"token punctuation\">.</span>uniform<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">&lt;=</span>b_response_prob<span class=\"token punctuation\">:</span>\n        b_vote <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>bernoulli<span class=\"token punctuation\">(</span>b_vote_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        results<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>b_vote<span class=\"token punctuation\">)</span>\n        group<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token string\">'b'</span><span class=\"token punctuation\">)</span>\n        i<span class=\"token operator\">+=</span><span class=\"token number\">1</span></code></pre>\n<p>The code above only simulates one poll. The following simulates 10 thousand different polls.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\">n_polls <span class=\"token operator\">=</span> <span class=\"token number\">10_000</span>\nnum_b_resps <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>poll_sample_size<span class=\"token operator\">//</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> p<span class=\"token operator\">=</span>b_response_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span>n_polls<span class=\"token punctuation\">)</span> <span class=\"token comment\"># tried to get 500 of each group</span>\n\nnum_a_resps <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>poll_sample_size <span class=\"token operator\">-</span> i <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> num_b_resps<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># Pollster needs 1000 respondents, depends on how many they get from b</span>\na_resps <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>num_a_resps<span class=\"token punctuation\">,</span> a_vote_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> n_polls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># a responses</span>\nb_resps <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>num_b_resps<span class=\"token punctuation\">,</span> b_vote_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> n_polls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># b responses</span>\n\nbiased_total <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>a_resps <span class=\"token operator\">+</span> b_resps<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">/</span>poll_sample_size\n\n<span class=\"token comment\">## Collect weights, will discuss below</span>\na_weight <span class=\"token operator\">=</span> a_prop_population<span class=\"token operator\">/</span><span class=\"token punctuation\">(</span>num_a_resps<span class=\"token operator\">/</span>poll_sample_size<span class=\"token punctuation\">)</span> <span class=\"token comment\"># Numerator is the proportion in the population</span>\nb_weight <span class=\"token operator\">=</span> b_prop_population<span class=\"token operator\">/</span><span class=\"token punctuation\">(</span>num_b_resps<span class=\"token operator\">/</span>poll_sample_size<span class=\"token punctuation\">)</span>\n\nipw_weighted_total <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>a_weight<span class=\"token operator\">*</span>a_resps <span class=\"token operator\">+</span> b_weight<span class=\"token operator\">*</span>b_resps<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">/</span>poll_sample_size</code></pre>\n<p>We can now plot what proportion of the population supports Hans according to each of these 10 thousand polls.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/7BkHuzcDp1-640.avif 640w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/7BkHuzcDp1-640.webp 640w\"><img alt=\"Samples drawn with bias compared to true distribution.\" loading=\"lazy\" decoding=\"async\" src=\"https://tristinb.github.io/img/7BkHuzcDp1-640.png\" width=\"640\" height=\"480\"></picture></p>\n<p>The plot below shows the polls are substantially biased against Hans' support. The average amount of support across all 10 thousand polls is 47 percent, rather than the true level of 54 percent. You can also notice very little overlap between the true distribution and the polls. If we run code to see how many of our samples are within three percent of the true value, we get the following:</p>\n<pre class=\"language-text\" tabindex=\"0\"><code class=\"language-text\">Proportion outside 3 percent:  0.9976</code></pre>\n<p>In other words, only 24 out of the 10 thousand polls were within 3 percentage points of the true value. This would occur despite sampling error alone suggesting that 950 should have fallen within 3 percentage points of the true value. If we assumed a 3 percent margin of error, we could be fairly confident Franz would win.</p>\n<p>From this example, we can see that substantial bias can result when one segment of the population does not respond to the poll and this segment also has different views than those more likely to respond. Fortunately, we can adjust for this bias, at least when we know who is under-responding.</p>\n<h2 id=\"correcting-bias-adding-variance\" tabindex=\"-1\">Correcting Bias, Adding Variance <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<p>The code above also included weights. Let's assume that the pollster knew the true distribution of groups A and B in the population, which we defined as 50/50. Let's also assume that the only factor that impacts how likely someone is to respond to the poll is what group they are in.</p>\n<p>Although many techniques exist to correct for bias when you have group-level characteristics, we can use a simple one here: inverse probability weighting (IPW). Essentially, IPM increases the weight for each response for the group that was under-sampled and decreases the weight for each response in the group that was over-sampled.</p>\n<p>The figure below shows the results we get if we adjust the biased draws above with IPW.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/dIXo2WUPri-640.avif 640w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/dIXo2WUPri-640.webp 640w\"><img alt=\"Biased draws corrected with IPW\" loading=\"lazy\" decoding=\"async\" src=\"https://tristinb.github.io/img/dIXo2WUPri-640.png\" width=\"640\" height=\"480\"></picture></p>\n<p>Although this distribution is centered close to the true value of 54 percent, notice that the samples are &quot;wider&quot; than the theoretical distribution. This means that each poll is noisier than expected. We can run code similar to the above to find what proportion falls outside +/- 3 percentage point from the correct value of .54:</p>\n<pre class=\"language-text\" tabindex=\"0\"><code class=\"language-text\">Proportion outside 3 percent:  0.1964</code></pre>\n<p>After this bias correction, we now have nearly 20 percent of each pall falling outside of +/- 3 percentage point from the true value -- substantially more than the five percent we would expect from sampling error alone.</p>\n<p>Unfortunately, pollster's efforts to adjust for bias often results in more variance. Because you may add substantial weight to a small number of respondents, the makeup of these particular respondents can cause poll results to fluctuate wildly. A notable example occured in 2016, when <a href=\"https://www.nytimes.com/2016/10/13/upshot/how-one-19-year-old-illinois-man-is-distorting-national-polling-averages.html\">one person was weighted around 30 times as much as the average respondent</a>. When this person was out of the sample Clinton led; when he was included Clinton trailed. This poll wasn't necessarily systematically pro or anti Clinton, but the inclusion of this one additional respondent made the poll's expected level of Clinton support to vary far beyond what sampling error alone would have us believe.</p>\n<h2 id=\"how-does-this-impact-professional-polls\" tabindex=\"-1\">How Does This Impact Professional Polls? <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<p>A 2018 paper by Shirani-Mehr and coauthors <sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/polls/\" id=\"fnref2\">[2]</a></sup> analyzed US gubernatorial, senatorial, and presidential election polls in the final three weeks of the campaign between 1998 and 2014 with the goal of disentangling the amount of bias and variance in the polls. They find that, on average, bias is about 2 percentage points. This bias isn't systematically for or against either party but fluctuates at random -- if there was a correlation with political party, it could be adjusted for.</p>\n<p>Additionally, the paper finds that variance is about 1.5 percentage points more than we would expect from sampling error alone. The authors speculate this is due to the methods pollsters use to account for bias. Taken together, the additional bias and variance suggests that rather than assuming polls are accurate to within +/- 3 percentage points, we should really assume they are accurate to within +/- 6 to 7 percentage points. This spread would have covered many of the polls in 2020, the biggest polling miss since 1980, where the average poll was off by <a href=\"https://aapor.org/wp-content/uploads/2022/11/Task-Force-on-2020-Pre-Election-Polling_Executive-Summary.pdf\">5.1 percent at the state level</a>.</p>\n<p>In addition to assuming the margin of error is much larger than 3 percent -- which doesn't even make sense in theory since we know there is more than sampling error leaking into polls -- we should think hard about who decides to respond to a poll when interpreting its results, since polls can fail drastically if biasness isn't accounted for.</p>\n<p>A recent poll following Israel's invasion of Gaza showed a surprisingly large number of Gen-Z respondents believed Hamas' murder of civilians was justified. This poll was taken as protests broke out across the country against Israel's invasion. During the 2020 George Floyd protests, protestors were systematically <a href=\"https://www.pewresearch.org/short-reads/2020/06/24/recent-protest-attendees-are-more-racially-and-ethnically-diverse-younger-than-americans-overall/\">younger than Americans as a whole</a>. If these age trends continued, the protests against Israel likely skewed Gen-Z. Protesting may also fires these activists up for their cause, making them more likely to respond to a pollster. If these protestors are also more likely to agree with more extreme statements -- perhaps just being caught in the moment -- then the amount of support for Hamas' use of violence would be drastically inflated. We can try to look toward other indicators to determine how plausible this explanation is. Or perhaps this poll is solid and more than 50 percent of young people support Hamas' act.</p>\n<!-- ## How Should we Interpret Polls? -->\n<!-- Given the declining response to surveys, many firms have resorted to using panels. Many of them, such as YouGov use a mix of panels and probabilistic sampling through methods such as random digit dialing to get their sample. However, one notable issue with panels is that they have a notoriously high rate of attrition -- people take one or two surveys and then never respond again. But the problem arises when those who choose to stay on panels are systematically different from the population with respect to the questions they are asked. For instance, people who like answering survey questions may also like Biden, but we have no measure of \"affinity for answering surveys\" to adjust for this bias. -->\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>We could calculate the value of N we would need for +/- 3 percent to cover 95 percent when the true value of the population is 0.54 as $$.03=1.96\\sqrt{\\frac{.54(1-.54)}{n}}$$ $$\\sqrt{n} = \\frac{1.96}{.03}\\sqrt{0.2484}$$ $$ n = 1060.28 $$ If we set our sample size in the example above to 1061 we will see the number get closer to 0.05. <a href=\"https://tristinb.github.io/blog/polls/\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n<li id=\"fn2\" class=\"footnote-item\"><p>Shirani-Mehr, Houshmand, David Rothschild, Sharad Goel, and Andrew Gelman. &quot;Disentangling bias and variance in election polls.&quot; Journal of the American Statistical Association 113, no. 522 (2018): 607-614. <a href=\"https://tristinb.github.io/blog/polls/\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2023-11-08T00:00:00Z"
		}
		
	]
}
