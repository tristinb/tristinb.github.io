{
	"version": "https://jsonfeed.org/version/1.1",
	"title": "Processing Beliefs",
	"language": "en",
	"home_page_url": "https://tristinb.github.io/",
	"feed_url": "https://tristinb.github.io/feed/feed.json",
	"description": "Just writing about stuff.",
	"author": {
		"name": "Tristin Beckman",
		"url": "https://tristinb.github.io/about"
	},
	"items": [
		{
			"id": "https://tristinb.github.io/blog/external_validity/",
			"url": "https://tristinb.github.io/blog/external_validity/",
			"title": "External Validity",
			"content_html": "<p>Machine learning models often degrade soon after they are launched. From widely publicized failures, like <a href=\"https://en.wikipedia.org/wiki/Google_Flu_Trends\">Google Flu Trends</a> and <a href=\"https://fortune.com/2022/06/02/zillow-6-billion-home-flipping-business-housing-market-fortune-500/\">Zillow's $6 billion home-flipping foray</a>, to less headline worthy cases such as accuracy dropping by <a href=\"https://proceedings.mlr.press/v97/recht19a/recht19a.pdf\">nearly 15 percent</a> in a replication study of the widely used ImageNet benchmark dataset, ML models often perform worse in the wild than practitioners hope.</p>\n<p>Most ML textbooks offer simple advice: gather new data and retrain the model. However, this only works when models degrade because the relationship between the features and the target shift, but the features still contain enough information to predict the target well. For example, a higher resolution camera may change how pixel values relate to the existence of a hot dog in an image, but it doesn't change the underlying relationship between pixels and the image's content.</p>\n<p>Retraining a model with new data will not help if models degrade for other reasons -- reasons long studied in the social sciences, under the name of <em>external validity</em>, which explores the extent to which models or theories perform well on new data<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/external_validity/\" id=\"fnref1\">[1]</a></sup>. Understanding threats to external validity can help us better understand how well our models may perform when deployed and give us a sense of what to do when they degrade.</p>\n<p>A machine learning, or statistical, model can be broken up into at least the following parts, all of which may differ between model development and deployment<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/external_validity/\" id=\"fnref2\">[2]</a></sup>:</p>\n<ul>\n<li>Y: the target that we want to explain or predict. This could be real-estate prices in Zillow's case, or whether an email is spam.</li>\n<li>X: The measured features of the sample. This can be everything we would use to try to predict house prices in the Zillow example, the words in an email or the pixel values in an image. We typically hope this sample is representative of the population to which we want to deploy our model.</li>\n<li>C: The unmeasured context. These are variables that we don't, or can't, measure when we train our model. This could be something like a geographic region for house prices or a different period of time.</li>\n</ul>\n<!-- - T: The treatment. In experiments, or causal models, we often want to measure an intervention's impact. The treatment could be a vaccine, a longer-mortgage, or a school voucher. -->\n<p>Starting with the target, during training we may only be able to use proxies for what we hope to capture in the world. For spam classification, we need to come up with a definition of spam that matches what our users conceptualize as spam. For example, how should we label an email that comes from an old acquaintance pitching their startup? Similarly, political opinion polls ask respondents how they would vote if the election were today. Does this match how they actually vote? If our proxy doesn't match the outcome that the model is hoping to explain or predict, the model will not perform well in the world. Collecting more data won't help.</p>\n<p>Moving to the sample, <a href=\"https://arxiv.org/abs/1902.10811\">Recht et al.</a> built new datasets closely matching the procedures to generate two popular ML benchmark datasets: CIFAR-10 and ImageNet. They then used a variety of models trained on the original datasets and found that they all did worse on the new data, with accuracy falling by 3-15 percent on CIFAR-10 and 11-15 percent on ImageNet. These large accuracy drops despite negligible differences in labeling, the authors argue, show that when the sample is even slightly different than the population where we want to deploy our model, we may see substantial degradation. Fortunately, in this case, gathering more data from the population and retraining our model typically improves it.</p>\n<p>Finally, we have context validity to understand how well the model will travel to new geographies, or time periods. <a href=\"https://www.cambridge.org/core/journals/american-political-science-review/article/elements-of-external-validity-framework-design-and-analysis/2D0914404C84B3F169732FF1D5E39420\">Egami and Hartman</a> point out that we can think of context validity as being like sample validity, but for features that either don't change or for which we don't have data within our study. For example, a study that predicts user behavior based on 20-year-olds in Florida does not tell us directly how our model will perform on 30-year-olds in Colorado. The same thing occurs when we look to the future. <a href=\"https://journals.sagepub.com/doi/10.1177/20531680231187271\">New technologies and new trends arise</a> that didn't exist in our training datasets. For example, the impact of writing assistant tools on student performance was likely much different in 2020, when tools were limited to simple style and grammar suggestions, than after ChatGPT's launch, when students could offload most of the writing process to the chatbot. These technological changes can break relationships that we could have previously used to make predictions. When these relationships are broken, not just tweaked, gathering more data and retraining our model won't improve it. Instead, we need to rethink the model fundamentally.</p>\n<p>Understanding different threats to external validity shows that simply gathering data and retraining a model only works in a minority of cases. If the way we define our target doesn't match what a model's end users care about, or if the world changes in ways that break relationships we used for prediction, simply collecting more data won't help.</p>\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/external_validity/\">#</a></h2>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>Typically, ML researchers perform a &quot;train/test split&quot; to try to get a sense of how well their model will perform on new data. However, this test data is typically a random subset of the training data, meaning the test comes from the same distribution as the training set. <a href=\"https://tristinb.github.io/blog/external_validity/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n<li id=\"fn2\" class=\"footnote-item\"><p><a href=\"https://www.cambridge.org/core/journals/american-political-science-review/article/elements-of-external-validity-framework-design-and-analysis/2D0914404C84B3F169732FF1D5E39420\">Egami and Hartman</a> also point out the treatment as another dimension that may not travel well. For example, in an experiment we may be able to ensure the placebo group and the treatment group don't interfere with one another, but this may be more difficult when an intervention is scaled up. <a href=\"https://tristinb.github.io/blog/external_validity/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2026-01-14T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/nfl_wk_14_2025/nfl_week_14_daggy/",
			"url": "https://tristinb.github.io/blog/nfl_wk_14_2025/nfl_week_14_daggy/",
			"title": "Week 14 NFL Predictions, Daggy vs Kalshi",
			"content_html": "<p>Last Thursday, I asked Daggy to run a handful of models on basic NFL data, choose the best one, and predict Week 14 games. For a baseline, I compared the predictions with <a href=\"https://kalshi.com/\">Kalshi</a>, an $11 billion prediction market that allows people in all 50 states to put money on NFL games.</p>\n<p>Daggy not only got one more game correct than Kalshi, but also achieved a better Brier score (lower is better). The table below shows the predictions and result for each game.</p>\n<table>\n<thead>\n<tr>\n<th>Matchup</th>\n<th>Winner</th>\n<th>Daggy Prob</th>\n<th>Kalshi Prob</th>\n<th>Result</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ARI vs LA</td>\n<td>LA</td>\n<td>68.3%</td>\n<td>82%</td>\n<td>Both ‚úì</td>\n</tr>\n<tr>\n<td>ATL vs SEA</td>\n<td>SEA</td>\n<td>59.4%</td>\n<td>74%</td>\n<td>Both ‚úì</td>\n</tr>\n<tr>\n<td>BAL vs PIT</td>\n<td>PIT</td>\n<td>46.9%</td>\n<td>29%</td>\n<td>Both ‚úó</td>\n</tr>\n<tr>\n<td>BUF vs CIN</td>\n<td>BUF</td>\n<td>69.5%</td>\n<td>72%</td>\n<td>Both ‚úì</td>\n</tr>\n<tr>\n<td>CLE vs TEN</td>\n<td>TEN</td>\n<td>36.6%</td>\n<td>36%</td>\n<td>Both ‚úó</td>\n</tr>\n<tr>\n<td>DET vs DAL</td>\n<td>DET</td>\n<td>65.3%</td>\n<td>62%</td>\n<td>Both ‚úì</td>\n</tr>\n<tr>\n<td>GB vs CHI</td>\n<td>GB</td>\n<td>62.5%</td>\n<td>73%</td>\n<td>Both ‚úì</td>\n</tr>\n<tr>\n<td>JAX vs IND</td>\n<td>JAX</td>\n<td>50.3%</td>\n<td>47%</td>\n<td>Daggy ‚úì</td>\n</tr>\n<tr>\n<td>KC vs HOU</td>\n<td>HOU</td>\n<td>51.3%</td>\n<td>36%</td>\n<td>Daggy ‚úì</td>\n</tr>\n<tr>\n<td>LAC vs PHI</td>\n<td>LAC</td>\n<td>48.7%</td>\n<td>45%</td>\n<td>Both ‚úó</td>\n</tr>\n<tr>\n<td>LV vs DEN</td>\n<td>DEN</td>\n<td>72.5%</td>\n<td>80%</td>\n<td>Both ‚úì</td>\n</tr>\n<tr>\n<td>MIN vs WAS</td>\n<td>MIN</td>\n<td>40.5%</td>\n<td>48%</td>\n<td>Both ‚úó</td>\n</tr>\n<tr>\n<td>NYJ vs MIA</td>\n<td>MIA</td>\n<td>46.4%</td>\n<td>57%</td>\n<td>Kalshi ‚úì</td>\n</tr>\n<tr>\n<td>TB vs NO</td>\n<td>NO</td>\n<td>41.7%</td>\n<td>21%</td>\n<td>Both ‚úó</td>\n</tr>\n<tr>\n<td><strong>TOTAL</strong></td>\n<td></td>\n<td><strong>Daggy: 8/14</strong></td>\n<td><strong>Kalshi: 7/14</strong></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Brier Score</strong></td>\n<td></td>\n<td><strong>0.22</strong></td>\n<td><strong>0.24</strong></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>I was skeptical of these predictions when I posted them to LinkedIn last Thursday. Not only was the data simple, with nothing on injuries or weather conditions, but Claude, which interfaces with Daggy, also asked Daggy to drop data before 2024 despite having data going back to 2000. The best model of the three Daggy trained only had seven features. Overall, the whole modeling process took about ten minutes and Daggy made better week 14 predictions than a prediction market that harnessed the wisdom of the crowds. We will see if this holds in week 15.</p>\n",
			"date_published": "2025-12-09T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/casino_bandits/",
			"url": "https://tristinb.github.io/blog/casino_bandits/",
			"title": "Losing money at video poker, with data science!",
			"content_html": "<p>When I play video poker, I search for &quot;corner&quot; machines since someone once told me those are the best. Despite following this advice, I rarely cash in big. Although some psychological factors may lead the casino to loosen up the corner machines, my assumption is that all the video poker machines have the same odds. But what if they didn't? If the casino really had a few machines that favored the gambler, could I cash in?</p>\n<p>Before analyzing some strategies, let's simplify our casino. Suppose that it costs $1 to play each machine, which pays $1 with some probability <em>p</em>. Since the casino can't be too tight if they want to attract gamblers, let's assume the optimal average payout across all machines is 0.48. Our toy casino only has two machines: one pays out 51 percent of the time and the other pays out 45 percent of the time, giving an average of 0.48.</p>\n<p>Our goal is to distinguish between the good and the bad machine as fast as possible in order to take advantage of the machine that pays out 51 percent of the time.</p>\n<p>We could try an A/B testing framework. As is standard, we would want 80 percent power, which means we need to have a large enough sample size to give us an 80 percent probability of rejecting the null hypothesis that the machines have the same underlying payoff. Then we could play the good machine until the casino kicked us out. To achieve 80 percent power given our machines' payoffs, we would need 2,174 total pulls, with half of them, or 1,087, coming from the bad machine. After this experiment, since our test has 80 percent power, we will identify and play the high paying machine 80 percent of the time, and in the other 20 percent, where we fail to detect a difference from the experiment, we will randomize between the machines.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/casino_bandits/\" id=\"fnref1\">[1]</a></sup> Taken together, running the experiment costs $86.96.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/casino_bandits/\" id=\"fnref2\">[2]</a></sup> But then we can take advantage of our knowledge. Our expected profit per pull is 0.8*($0.02) + 0.2*(-$0.04) = $0.008. For T - 2,174 exploitation steps, our total profit is: -$86.96 + (T-2,174)($0.008).</p>\n<p>Rather than having a fixed number of samples from each machine before determining which is best, <em>bandit algorithms</em>, which get their name from slot machines, dynamically adapt their choice of what machine to play next based on the previous outcomes. Several bandit algorithms exist, but one of the most effective, and common, is the Upper Confidence Bound 1 (UCB1), which assumes payoffs are bounded between zero and one. At each time step, for each machine, we calculate the average of past pulls plus an upper confidence bound, which is based on the number of previous draws from that specific machine and our current time step. We then select the machine with the highest upper confidence bound, receive a payout, and repeat. This simple algorithm has near-optimal performance and protects against playing a wildly worse machine too many times because we only play a machine if its upper confidence bound is large, but since the confidence bound shrinks with each play, we quickly abandon bad machines.</p>\n<p>However, unlike in the A/B testing case, we cannot easily calculate the expected profit, in part because the choices are made dynamically. Instead, we ran simulations to estimate expected profit. The figure below shows the cumulative profit after one thousand simulations, each containing 20,000 pulls. The chart shows the mean, 5th--95th percentiles of the UCB1 algorithm along with the expected profit from the A/B test.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/6sv2tysa5b-640.avif 640w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/6sv2tysa5b-640.webp 640w\"><img alt=\"Profit for UCB and A/B\" loading=\"lazy\" decoding=\"async\" class=\"responsive-image\" style=\"max-width: 100%; height: auto;\" src=\"https://tristinb.github.io/img/6sv2tysa5b-640.png\" width=\"640\" height=\"480\"></picture></p>\n<p>The figure above shows that the UCB1 algorithm typically experiences higher profit than the A/B test. Notice that the A/B test has two linear segments, one for the exploration phase, where it loses money, and one for exploitation, where it makes money. But the A/B test only chooses the correct machine with 80 percent probability, and never improves no matter how many draws it makes. The bandit algorithm, however, continuously improves. As it takes more samples, it plays the better machine more, leading its profits to diverge from the A/B testing strategy. The table below shows the cumulative profit at selected milestones, including breakeven points from the figure above.</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:right\">Step</th>\n<th style=\"text-align:right\">UCB Mean Profit (5th‚Äì95th percentile)</th>\n<th style=\"text-align:right\">A/B Expected Profit</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:right\">1,000</td>\n<td style=\"text-align:right\">-$20.23 (-$37.01 to -$5.01)</td>\n<td style=\"text-align:right\">-$40.00</td>\n</tr>\n<tr>\n<td style=\"text-align:right\">3,000</td>\n<td style=\"text-align:right\">-$32.09 (-$70.98 to $2.01)</td>\n<td style=\"text-align:right\">-$80.35</td>\n</tr>\n<tr>\n<td style=\"text-align:right\">6,000</td>\n<td style=\"text-align:right\">-$23.94 (-$83.98 to $26.42)</td>\n<td style=\"text-align:right\">-$56.35</td>\n</tr>\n<tr>\n<td style=\"text-align:right\">9,000</td>\n<td style=\"text-align:right\">-$2.50 (-$78.73 to $61.82)</td>\n<td style=\"text-align:right\">-$32.35</td>\n</tr>\n<tr>\n<td style=\"text-align:right\"><strong>9,268</strong></td>\n<td style=\"text-align:right\"><strong>$0.00 (-$77.73 to $65.01)</strong></td>\n<td style=\"text-align:right\">-$30.21</td>\n</tr>\n<tr>\n<td style=\"text-align:right\">12,000</td>\n<td style=\"text-align:right\">$28.07 (-$59.26 to $104.33)</td>\n<td style=\"text-align:right\">-$8.35</td>\n</tr>\n<tr>\n<td style=\"text-align:right\"><strong>13,045</strong></td>\n<td style=\"text-align:right\">$40.25 (-$50.06 to $119.17)</td>\n<td style=\"text-align:right\"><strong>$0.01</strong></td>\n</tr>\n<tr>\n<td style=\"text-align:right\">15,000</td>\n<td style=\"text-align:right\">$63.94 (-$33.52 to $150.52)</td>\n<td style=\"text-align:right\">$15.65</td>\n</tr>\n<tr>\n<td style=\"text-align:right\">20,000</td>\n<td style=\"text-align:right\">$129.57 ($17.82 to $227.83)</td>\n<td style=\"text-align:right\">$55.65</td>\n</tr>\n</tbody>\n</table>\n<p>The table illustrates that the bandit algorithm breaks even nearly 4,000 steps before the A/B test. Furthermore, as highlighted in the figure above, by continuously improving, the bandit algorithm makes nearly 2.5X more profit than the A/B testing strategy after 20,000 steps. In this casino, the bandit algorithm clearly dominates the A/B test.</p>\n<p>But no matter the strategy, notice the number of pulls I would need to break even. Let's say I can play one hand every 5 seconds, or 12 hands a minute. That is 9,268/12 or 772 minutes, which is 12.8 hours of playing video poker. Using the A/B testing strategy, I would need 1,087 minutes, or 18.1 hours of playing these two machines just to break even. This shows that although we could profit over the long term, as Keynes said, that much video poker would leave us dead before cashing in.</p>\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/casino_bandits/\">#</a></h2>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>I am assuming away type S errors here, where we falsely conclude the bad machine is the better one. <a href=\"https://tristinb.github.io/blog/casino_bandits/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n<li id=\"fn2\" class=\"footnote-item\"><p>Expected loss per pull during 50/50 exploration is 0.5(+$0.02) + 0.5(-$0.10) = -$0.04. Over 2,174 pulls: 2,174 √ó (-$0.04) = $86.96 <a href=\"https://tristinb.github.io/blog/casino_bandits/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2025-11-04T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/mortgage_rates/",
			"url": "https://tristinb.github.io/blog/mortgage_rates/",
			"title": "Mortgage rates under various economic scenarios",
			"content_html": "<p>Mortgage rates just hit their <a href=\"https://fred.stlouisfed.org/series/MORTGAGE30US\">lowest levels</a> in nearly a year. With the market predicting the Fed to cut rates in September, how much further can they drop? Although much depends on both the Fed's decision and the overall economic outlook, we can use Daggy to build a model of how interest rates impact mortgage rates, then consider various economic scenarios to understand where mortgage rates are likely to fall under several economic scenarios.</p>\n<p>I began by loading data from the Federal Reserve Economic Data (FRED) on the <a href=\"https://fred.stlouisfed.org/series/DGS2\">2-year</a> and <a href=\"https://fred.stlouisfed.org/series/DGS10\">10-year</a> treasury yields as well as the <a href=\"https://fred.stlouisfed.org/series/MORTGAGE30US\">30-year-fixed rate mortgage average</a> into Daggy. The dataset included 812 weekly observations spanning from 2010 to the present. I then asked Daggy the following:</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/LYNF-fytM5-1578.avif 1578w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/LYNF-fytM5-1578.webp 1578w\"><img alt=\"Asking Claude: Use Daggy to model the relationship between the 10 year yield and 30 year fixed mortgage rates. How about the 2 year yield? What if I used the 10 year 2 year spread? Build a few models to test the robustness of this relationship\" loading=\"lazy\" decoding=\"async\" class=\"responsive-image\" style=\"max-width: 100%; height: auto;\" src=\"https://tristinb.github.io/img/LYNF-fytM5-1578.png\" width=\"1578\" height=\"784\"></picture></p>\n<p>It ran several models and returned the following table:</p>\n<h4 id=\"model-performance-comparison\" tabindex=\"-1\">Model Performance Comparison <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/mortgage_rates/\">#</a></h4>\n<table>\n<thead>\n<tr>\n<th>Rank</th>\n<th>Model</th>\n<th>R¬≤</th>\n<th>RMSE</th>\n<th>WAIC</th>\n<th>Key Insight</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ü•á</td>\n<td>10-Year + Yield Spread</td>\n<td>94.5%</td>\n<td>0.275pp</td>\n<td>-34.4</td>\n<td>Best overall performance</td>\n</tr>\n<tr>\n<td>ü•à</td>\n<td>10-Year Only</td>\n<td>89.0%</td>\n<td>0.404pp</td>\n<td>-276.4</td>\n<td>Missing the spread information hurts accuracy</td>\n</tr>\n<tr>\n<td>ü•â</td>\n<td>2-Year Only</td>\n<td>79.8%</td>\n<td>0.546pp</td>\n<td>-512</td>\n<td>Short-term rates alone aren't enough</td>\n</tr>\n</tbody>\n</table>\n<p>Notice the R-squared of 94.5 percent shows that with just two variables we can explain nearly 95 percent of the variation in 30-year mortgage rates. The WAIC is used to predict how well the model would perform out of sample. Although this is difficult to interpret, AI tools like Claude know that higher values (those closer to zero) are typically better, so it can intelligently choose which model to use.</p>\n<p>To further understand model performance, I then asked Daggy to provide me with the model's worst predictions, as follows:</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/DC19noB67S-1698.avif 1698w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/DC19noB67S-1698.webp 1698w\"><img alt=\"Asking Claude: What were the worst predictions?\" loading=\"lazy\" decoding=\"async\" class=\"responsive-image\" style=\"max-width: 100%; height: auto;\" src=\"https://tristinb.github.io/img/DC19noB67S-1698.png\" width=\"1698\" height=\"992\"></picture></p>\n<p>It provided an artifact that included the table below, showing that the worst results were well within 1 percentage point of the true value and occurred at the onset of the COVID pandemic.</p>\n<hr>\n<h4 id=\"even-during-crisis-the-model-holds-strong\" tabindex=\"-1\">Even During Crisis, the Model Holds Strong <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/mortgage_rates/\">#</a></h4>\n<table>\n<thead>\n<tr>\n<th>Date</th>\n<th>Actual Rate</th>\n<th>Predicted</th>\n<th>Error</th>\n<th>Context</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>April 23, 2020</td>\n<td>3.33%</td>\n<td>2.5%</td>\n<td>+0.83pp</td>\n<td>COVID peak volatility</td>\n</tr>\n<tr>\n<td>April 16, 2020</td>\n<td>3.65%</td>\n<td>2.49%</td>\n<td>+0.82pp</td>\n<td>COVID peak volatility</td>\n</tr>\n<tr>\n<td>April 2, 2020</td>\n<td>3.33%</td>\n<td>2.52%</td>\n<td>+0.81pp</td>\n<td>COVID peak volatility</td>\n</tr>\n</tbody>\n</table>\n<p>The table above shows that even during extreme market turbulence, our model stayed within 1 percentage point of the true values. Given this robust relationship, we can now consider forward-looking scenarios. To do this effectively, we need to understand how different economic conditions shape the yield curve, or the relationship between the bond's term and its yield.</p>\n<p>Outside of periods like quantitative easing (QE) the Fed sets overnight bank rates. Overnight rates then influence, but don't solely determine, longer-term rates like the 2 year and 10 year. Mortgage rates are closely tied to longer-term rates, which the Fed doesn't directly control. The yield curve's slope -- basically the difference between long-term and short-term rates -- is notoriously difficult to predict. Economic theory argues the slope depends on the market's expectations of future yields as well as a premium for holding longer-term bonds. Both of these factors are difficult to observe and can fluctuate based on many factors, such as expected inflation and unemployment. However, yield curve's rough shape can provide insight into the market's view on future economic conditions. Specifically, consider how the following expectations would shape the yield curve:</p>\n<p><strong>Inflation Fears</strong> Higher inflation means the Fed will likely need to raise rates in the future. Expectations of future rates result in a steep, positively sloped yield curve, where the ten year yield is much greater than the two year yield.</p>\n<p><strong>Recession Fears</strong> A slowing economy means the Fed may need to cut rates. Expectations of lower rates result in a negatively sloped yield curve, where the ten year's yield is less than the two year's. This is also known as an &quot;inverted yield curve&quot;. An example of this occurred in August 2019, which saw the ten year at 1.49% and the two year at 1.53%.</p>\n<p><strong>Soft Landing/Normalization</strong> Because of the premium for holding long-term bonds, yield curves typically slope upward. But if investors steady rates, the slope will be flatter than in the inflationary fears scenario.</p>\n<p><strong>Economic Boom</strong> Typically economic booms are associated with higher interest rates, both because booms feed inflation and a higher demand for investment consistent with rosy economic outlooks cause rates to rise. This scenario results in a steeply sloped yield curve with the 10 year rate higher than the 2 year rate.</p>\n<p>Now we can use our above trained model to determine a likely range of mortgage rates under these scenarios. I asked Claude the following:</p>\n<p><em>Use Daggy to run a few scenarios here. For context, the current 10 year yield is 4.29% and the two year is 3.74% Then put this into a table. Let's think about broad economic scenarios: if investors expect inflation, we will have a positive sloped yield curve. If they expect a recession we will have an inverted yield curve. During normal circumstances it will be positive sloped, but less extreme than when investors expect inflation. We can also think about a stagflation and a boom.</em></p>\n<p>and it returned the table below.</p>\n<h4 id=\"economic-scenarios-and-mortgage-rate-projections\" tabindex=\"-1\">Economic Scenarios and Mortgage Rate Projections <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/mortgage_rates/\">#</a></h4>\n<table>\n<thead>\n<tr>\n<th>Scenario</th>\n<th>Economic Expectation</th>\n<th>10Y Yield</th>\n<th>2Y Yield</th>\n<th>Spread</th>\n<th>Predicted Mortgage Rate</th>\n<th>90% Confidence Interval</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>üîµ Current</td>\n<td>Normal Growth</td>\n<td>4.29%</td>\n<td>3.74%</td>\n<td>+0.55%</td>\n<td>6.52%</td>\n<td>6.33% - 6.71%</td>\n</tr>\n<tr>\n<td>üü¢ Normal Growth</td>\n<td>Steady Economy</td>\n<td>4.00%</td>\n<td>3.25%</td>\n<td>+0.75%</td>\n<td>6.13%</td>\n<td>5.97% - 6.30%</td>\n</tr>\n<tr>\n<td>üî¥ Recession</td>\n<td>Economic Downturn</td>\n<td>3.00%</td>\n<td>3.50%</td>\n<td>-0.50%</td>\n<td>5.43%</td>\n<td>5.26% - 5.60%</td>\n</tr>\n<tr>\n<td>üü† Inflation</td>\n<td>Rising Prices</td>\n<td>5.50%</td>\n<td>4.00%</td>\n<td>+1.50%</td>\n<td>7.55%</td>\n<td>7.23% - 7.87%</td>\n</tr>\n<tr>\n<td>üü° Stagflation</td>\n<td>Inflation + Slow Growth</td>\n<td>5.00%</td>\n<td>4.50%</td>\n<td>+0.50%</td>\n<td>7.32%</td>\n<td>7.06% - 7.58%</td>\n</tr>\n<tr>\n<td>üü£ Boom</td>\n<td>Strong Growth + Inflation</td>\n<td>6.00%</td>\n<td>4.00%</td>\n<td>+2.00%</td>\n<td>7.94%</td>\n<td>7.56% - 8.33%</td>\n</tr>\n</tbody>\n</table>\n<p>Without further prompting, it also provided a detailed analysis of the table. Two surprises it pointed out were the following (which I am quoting):</p>\n<ol>\n<li>\n<p><strong>Recession vs Boom Spread:</strong> Despite recession having the lowest 10Y yield (3.00%), mortgage rates only drop to 5.43% due to the inverted yield curve penalty</p>\n</li>\n<li>\n<p><strong>Curve Shape Power:</strong> The boom scenario (6.00% 10Y) has higher mortgage rates (7.94%) than pure yield levels would suggest, but the steep +2.00% curve actually helps - without it, rates could be even higher!</p>\n</li>\n</ol>\n<p>It also provided more logic behind why we would see the relationships that we do. For example, it pointed out that during an economic boom high growth expectations typically drive up rates. But it also noted that the yield curve's slope also played an important role, noting that &quot;Every +0.25% of additional curve steepness reduces mortgage rates by ~0.15%.&quot;</p>\n<p>The model shows that should the market forecast a huge economic boom, or if inflation takes off, <em>mortgage rates are unlikely to fall much further</em>. But if it forecasts solid growth, or should we fall into a recession, then rates are likely to continue to fall.</p>\n<p>Although predicting the future may be impossible, we can still prepare for it through scenario analysis. Here we were able to get a sense of how mortgage rates may evolve given different macroeconomic environments. With just a few questions, Daggy built and evaluated several models. It found a model that was extremely predictive with just two variables, then used that model to consider various economic scenarios to understand likely mortgage rates.</p>\n",
			"date_published": "2025-08-18T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/geopolitical_shocks_stocks/",
			"url": "https://tristinb.github.io/blog/geopolitical_shocks_stocks/",
			"title": "Geopolitical Shocks and Stocks",
			"content_html": "<p>Geopolitical shocks typically have little lasting impact on US stocks. Research by <a href=\"https://privatebank.jpmorgan.com/nam/en/insights/markets-and-investing/how-do-geopolitical-shocks-impact-markets\">JP Morgan</a> studied 36 events, beginning with Germany's invasion of France and ending with Russia's invasion of Ukraine, and found that the six month return starting from the day of a shock was indistinguishable from the return over any random six-month period that didn't cover a shock. Intuitively, geopolitics should play a substantial role in stock prices, but research consistently shows that they rarely do. Basic financial modeling provides insight into both why this is the case and what to look for the next time a global event causes the financial press to fret.</p>\n<p>Economists and investors from Irving Fisher to Benjamin Graham and his prot√©g√© Warren Buffett have long argued that a company's cash flows over the long-run determine a stock's intrinsic value. Cash flows are fundamental because they can be reinvested into the company to fuel growth or paid back to an investor via dividends or stock buybacks.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/geopolitical_shocks_stocks/\" id=\"fnref1\">[1]</a></sup> The goal in this valuation approach is to buy companies priced below their intrinsic valuation and sell those that are overpriced. Although stocks may fluctuate for various reasons in the short-term, value investors argue that cash flows over the long run are what truly drives returns.</p>\n<p>Since cash flows in the long run shape returns, stock prices should reflect the market's best guess about these future cash flows. An event that leads investors to revise this guess should then impact the stock's price. Academic/investor Michael Mauboussin and Alfred Rappaport emphasize three fundamental drivers of a company's valuation where shifts can impact a stock's price by changing the market's expectation of future cash flows: 1) sales/revenue growth 2) operating margins and 3) incremental investment.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/geopolitical_shocks_stocks/\" id=\"fnref2\">[2]</a></sup> These three channels can offer guidance into a geopolitical shock's impact on equities.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/geopolitical_shocks_stocks/\" id=\"fnref3\">[3]</a></sup></p>\n<p>According to <a href=\"https://www.goldmansachs.com/insights/articles/how-tariffs-are-forecast-to-affect-us-stocks\">Goldman Sachs</a> about 28 percent of the revenues for S&amp;P 500 companies come from abroad. But large US companies in the S&amp;P 500 are globally diversified, meaning they typically have few, if any, sales in countries where crises generally occur. For investors to update their expectations of sales growth sufficiently to sell their shares, the shock would likely need to be regional or global and hit several export markets. Therefore, because most revenues coming from within the US and those who export have diversified markets, a shock would have to hit a company's vital export markets quite hard to cause long-term stock price declines.</p>\n<p>Although large companies have diversified sales, they may have concentrated supply chains where shocks can negatively impact both operating margins and incremental investment. Operating margins relate to the costs of doing business in the short term, meaning it excludes things like financing and long-term investments. If input prices increase, operating margins will fall. The 1970s oil shock was the one event in the above JP Morgan report that had lasting impacts on equity prices as high oil prices increased costs across the economy.</p>\n<p>But not all shocks drive up prices, in part because of the dollar's role in the international financial system. Typically, crises lead investors to invest in safe assets, and US government bonds are considered the safest. This &quot;flight to safety&quot; can strengthen the dollar, thereby making imports cheaper. Since most imports to the US are used in <a href=\"https://www.bis.org/publ/arpdf/ar2025e1.pdf\">intermediate goods</a>, a decrease in import prices can improve operating margins, all else equal. Although many commodities, such as oil, are priced in dollars, and a stronger dollar can make a company's exports relatively less competitive, for many large firms, a stronger dollar can reduce operating costs.</p>\n<p>Some firms may own, or be significant investors in, factories abroad. If a shock hits these factories, these firms may need to diversify. Although being forced to make new investments in property, plants, and equipment may be an inefficient use of their capital, a diversified supply chain provides resilience to future shocks, thereby reducing the uncertainty of future cash flows, which increases their present value. For long-term focused investors, this diversification may be a net positive, cancelling out the negative short-term impacts on the stock price.</p>\n<p>We can see some of these drivers at play after Russia's invasion of Ukraine. McDonald's was one of the most exposed companies to the war with nearly <a href=\"https://corporate.mcdonalds.com/content/dam/sites/corp/nfl/pdf/Russia%20and%20Ukraine%20Supplemental%20Schedule.pdf\">9 percent of its revenues</a> coming from the two countries. But as the following table shows, its stock outperformed the S&amp;P 500 (measured by the SPY index) throughout the year following Russia's invasion.</p>\n<table>\n<thead>\n<tr>\n<th>Date</th>\n<th>SPY Close</th>\n<th>MCD Close</th>\n<th>SPY Pct. Change</th>\n<th>MCD Pct. Change</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2022-02-24</td>\n<td>407.46</td>\n<td>226.22</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>2022-05-25</td>\n<td>379.21</td>\n<td>226.53</td>\n<td>-6.93</td>\n<td>0.14</td>\n</tr>\n<tr>\n<td>2022-08-23</td>\n<td>395.21</td>\n<td>243.21</td>\n<td>-3.01</td>\n<td>7.51</td>\n</tr>\n<tr>\n<td>2022-11-21</td>\n<td>379.74</td>\n<td>257.67</td>\n<td>-6.80</td>\n<td>13.90</td>\n</tr>\n<tr>\n<td>2023-02-24</td>\n<td>383.21</td>\n<td>248.89</td>\n<td>-5.95</td>\n<td>10.02</td>\n</tr>\n</tbody>\n</table>\n<p>If we took the geopolitical shock and potential revenue loss at face value, we may have expected a significant drop in its stock price. Although 9 percent of revenue seems substantial, McDonald's owned and operated 100 percent of its restaurants in Ukraine and 84 percent of those in Russia, making this revenue come with high operating costs. Subtracting the cost of operating these restaurants caused this 9 percent of total revenue to equal less than 3 percent of its total operating income. These low-margin company-operated operations contrasted with McDonald's high-margin franchise model, likely making these stores less valuable to investors. Furthermore, this income exposure seems relatively small considering the broader 2022 macroeconomic environment.</p>\n<p>Post-pandemic inflation led to significant Fed tightening, with prominent economists <a href=\"https://www.bloomberg.com/news/articles/2022-07-01/summers-says-risk-of-2022-recession-climbing-may-damp-inflation\">predicting a recession by the end of 2022</a>. As <a href=\"https://www.economist.com/business/2025/08/07/mcdonalds-secret-sauce-plus-a-pickle-or-two\">the Economist</a> notes, McDonald's in the US is relatively insulated from inflation because it makes most of its revenue through franchise fees and taking a fixed percent of total sales (not profits). Simultaneously, it is also a good bet in the event of a recession, as its low prices attract more price-conscious consumers. Therefore, considering the broad macroeconomic context, investors may have liked McDonald's freeing up a substantial amount of capital by shutting their relatively low-return, low-franchise-fee, operations in Russia and Ukraine. As such, over the next year, McDonald's significantly outperformed the S&amp;P 500 even though on paper it seemed quite exposed to the war in Ukraine.</p>\n<p>Despite our intuition, and what we read about in the financial press, empirical studies consistently find minimal impact from geopolitical shocks. These findings are consistent with valuation approaches to equities, as shocks often leave a stock's core value drivers relatively unscathed. This is not to say geopolitics never matters, but when the next crisis occurs, analyzing fundamental value drivers can help us better assess how much that shock will impact stocks.</p>\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/geopolitical_shocks_stocks/\">#</a></h2>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>But since these cash flows are only available in the future, and $100 today is worth more than $100 in a year, simply because you can invest the $100 in a treasury bill and get a positive return at almost zero risk, we need to discount these future cash flows by at least the cost of capital. This &quot;discount rate&quot; serves to translate the future value of cash flows to the present value. <a href=\"https://tristinb.github.io/blog/geopolitical_shocks_stocks/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n<li id=\"fn2\" class=\"footnote-item\"><p>Michael Mauboussin and Alfred Rappaport. 2020. Expectations Investing. <a href=\"https://tristinb.github.io/blog/geopolitical_shocks_stocks/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n<li id=\"fn3\" class=\"footnote-item\"><p>But keep in mind, the threshold to sell may be large, since investors may need a new opportunity to invest in, and many opportunities could be adversely impacted by the shock. Similarly, because selling a stock incurs tax liabilities any new opportunity must at least cover this loss. <a href=\"https://tristinb.github.io/blog/geopolitical_shocks_stocks/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2025-08-13T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/july_sp500/july_stock_returns/",
			"url": "https://tristinb.github.io/blog/july_sp500/july_stock_returns/",
			"title": "Is July really a bad month for stocks?",
			"content_html": "<p>While having lunch with my mom in Idaho, I overheard someone at the table next to us say that July tends to be a down month for stocks. This seemed strange. If a month is predictably slow, there should be an opportunity to profit until that opportunity, and predictability, disappears. I decided to test this claim with <a href=\"https://www.daggydata.com/\">Daggy</a>.</p>\n<p>Although our table neighbor never mentioned any particular stock, I pulled SPY data (which tracks the S&amp;P 500) from January 2010 to December 2024. I defined monthly return as the percentage change from the stock's opening value on the first day of the month to the close on the last day.</p>\n<p>I then opened Claude and asked for average returns and standard deviations. It returned the following table:</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/FuG5gRfaSy-1604.avif 1604w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/FuG5gRfaSy-1604.webp 1604w\"><img alt=\"Claude question\" loading=\"lazy\" decoding=\"async\" class=\"responsive-image\" style=\"max-width: 100%; height: auto;\" src=\"https://tristinb.github.io/img/FuG5gRfaSy-1604.png\" width=\"1604\" height=\"972\"></picture></p>\n<p>It returned the following table:</p>\n<table>\n<thead>\n<tr>\n<th>Month</th>\n<th>Mean Monthly Return (%)</th>\n<th>Std Dev of Monthly Return (%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Jan</td>\n<td>0.65</td>\n<td>4.17</td>\n</tr>\n<tr>\n<td>Feb</td>\n<td>1.11</td>\n<td>3.71</td>\n</tr>\n<tr>\n<td>Mar</td>\n<td>1.17</td>\n<td>4.54</td>\n</tr>\n<tr>\n<td>Apr</td>\n<td>1.48</td>\n<td>5.24</td>\n</tr>\n<tr>\n<td>May</td>\n<td>0.09</td>\n<td>4.06</td>\n</tr>\n<tr>\n<td>Jun</td>\n<td>0.71</td>\n<td>4.01</td>\n</tr>\n<tr>\n<td>Jul</td>\n<td>2.76</td>\n<td>3.00</td>\n</tr>\n<tr>\n<td>Aug</td>\n<td>-0.58</td>\n<td>3.86</td>\n</tr>\n<tr>\n<td>Sep</td>\n<td>-0.76</td>\n<td>4.26</td>\n</tr>\n<tr>\n<td>Oct</td>\n<td>2.03</td>\n<td>4.85</td>\n</tr>\n<tr>\n<td>Nov</td>\n<td>3.08</td>\n<td>2.98</td>\n</tr>\n<tr>\n<td>Dec</td>\n<td>0.35</td>\n<td>3.99</td>\n</tr>\n</tbody>\n</table>\n<p>I then asked it to build me a chart of this data that I could download as a png. It, uh, complied.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/QPV6Wq_FrH-1530.avif 1530w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/QPV6Wq_FrH-1530.webp 1530w\"><img alt=\"SPY monthly returns\" loading=\"lazy\" decoding=\"async\" class=\"responsive-image\" style=\"max-width: 100%; height: auto;\" src=\"https://tristinb.github.io/img/QPV6Wq_FrH-1530.png\" width=\"1530\" height=\"1536\"></picture></p>\n<p>Rather than being down, July is the second strongest month. But the table above shows the standard deviations are often larger than the means themselves, suggesting there's substantial unexplained variation. This variation could be driven by systematic factors‚Äîyear effects like COVID's 2020 fluctuations, 2022's doldrums, momentum from previous months, or other factors. With Daggy we can easily build statistical models that account for these other factors.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/aMmWaRTk9H-1536.avif 1536w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/aMmWaRTk9H-1536.webp 1536w\"><img alt=\"Claude building statistical models via Daggy\" loading=\"lazy\" decoding=\"async\" class=\"responsive-image\" style=\"max-width: 100%; height: auto;\" src=\"https://tristinb.github.io/img/aMmWaRTk9H-1536.png\" width=\"1536\" height=\"868\"></picture></p>\n<p>Daggy built two models: one estimating the month effect and the other adjusting for the year when estimating the month effect. Although July's estimate was slightly positive, it was not statistically significant in either model. But maybe we have some &quot;reversion to the mean&quot;, where strong months tend to be followed by weak months and vice-versa? Perhaps this washes out the month effect? Claude knew how to frame this question to Daggy as a &quot;lagged dependent variable&quot; then included it in its analysis. Although the analysis showed apparent mean reversion, with strong months followed by weaker months, July's impact remained small and statistically insignificant. We asked claude to account for linear and cubic time trends. This eliminated mean reversion, but July remained weak.</p>\n<p>Overall, Daggy trained 8 models. I then asked Claude which model was the &quot;best&quot; and how well they performed, it then returned the table below:</p>\n<h2 id=\"model-performance-summary\" tabindex=\"-1\">Model Performance Summary <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/july_sp500/july_stock_returns/\">#</a></h2>\n<table>\n<thead>\n<tr>\n<th>Rank</th>\n<th>Model</th>\n<th>WAIC</th>\n<th>R¬≤</th>\n<th>Key Features</th>\n<th>Winner?</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>üèÜ <strong>1</strong></td>\n<td><strong>Month Only</strong></td>\n<td><strong>-262.86</strong></td>\n<td><strong>8.8%</strong></td>\n<td>Seasonal effects only</td>\n<td>‚úÖ <strong>BEST</strong></td>\n</tr>\n<tr>\n<td>2</td>\n<td>Pure Mean Reversion</td>\n<td>-265.89</td>\n<td>0.8%</td>\n<td>Lagged return only</td>\n<td>‚ùå</td>\n</tr>\n<tr>\n<td>3</td>\n<td>Month + Mean Reversion</td>\n<td>-269.40</td>\n<td>11.7%</td>\n<td>Seasonal + lag effects</td>\n<td>‚ùå</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Month + Year (Categorical)</td>\n<td>-273.77</td>\n<td>15.3%</td>\n<td>Seasonal + year dummies</td>\n<td>‚ùå</td>\n</tr>\n<tr>\n<td>5</td>\n<td>Month + Year (Continuous)</td>\n<td>-274.58</td>\n<td>8.6%</td>\n<td>Seasonal + linear year</td>\n<td>‚ùå</td>\n</tr>\n<tr>\n<td>6</td>\n<td>Time Trends Only</td>\n<td>-275.35</td>\n<td>17.6%</td>\n<td>Linear/quadratic/cubic time</td>\n<td>‚ùå</td>\n</tr>\n<tr>\n<td>7</td>\n<td>Month + Year + Mean Reversion</td>\n<td>-276.45</td>\n<td>18.1%</td>\n<td>Full model with years</td>\n<td>‚ùå</td>\n</tr>\n<tr>\n<td>8</td>\n<td>Time + Mean Reversion</td>\n<td>-341.20</td>\n<td>20.3%</td>\n<td>Time trends + lag</td>\n<td>‚ùå</td>\n</tr>\n</tbody>\n</table>\n<p>The table shows that no model fit the data particularly well.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/july_sp500/july_stock_returns/\" id=\"fnref1\">[1]</a></sup> The best model by WAIC, which estimates out of sample performance, included only month effects. But its R-squared was just 8.8%, meaning more than 90 percent of the variation in the training data remained unexplained.</p>\n<p>The table below shows the estimates for July across several models. The coefficients show July's estimated deviation from the average monthly returns.</p>\n<h2 id=\"july-effect-analysis\" tabindex=\"-1\">July Effect Analysis <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/july_sp500/july_stock_returns/\">#</a></h2>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>July Coefficient</th>\n<th>95% Confidence Interval</th>\n<th>Statistically Significant?</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Month Only</td>\n<td>-0.009</td>\n<td>[-0.343, +0.303]</td>\n<td>‚ùå <strong>NO</strong></td>\n</tr>\n<tr>\n<td>Month + Year Dummies</td>\n<td>-0.076</td>\n<td>[-0.309, +0.146]</td>\n<td>‚ùå <strong>NO</strong></td>\n</tr>\n<tr>\n<td>Month + Mean Reversion</td>\n<td>-0.052</td>\n<td>[-0.295, +0.224]</td>\n<td>‚ùå <strong>NO</strong></td>\n</tr>\n<tr>\n<td>Month + Time Trends + Mean Reversion</td>\n<td>-0.068</td>\n<td>[-0.253, +0.118]</td>\n<td>‚ùå <strong>NO</strong></td>\n</tr>\n</tbody>\n</table>\n<p>The table shows we are unlikely to have any investing opportunities in July.</p>\n<h2 id=\"conclusion\" tabindex=\"-1\">Conclusion <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/july_sp500/july_stock_returns/\">#</a></h2>\n<p>Although our lunch neighbor had the wrong take about July, he wouldn't have done much better had he looked at the raw data alone. Daggy's statistical analysis showed that July's strength over the past 15 years is typical given random variation of the S&amp;P 500's overall trend. We built and analyzed several models all showing that time-related factors failed to even predict the training data well. If they can only moderately predict the training data, they will struggle even more to predict the future.</p>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>WAIC (Widely Applicable, or Watanabe-Akaike, information criterion) estimates how well the model will predict on out of sample data, with values closer to zero being better. R-squared estimates how much of the training data's variation the model explains. High R-squared values won't typically travel to new data. <a href=\"https://tristinb.github.io/blog/july_sp500/july_stock_returns/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2025-07-25T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/llm_utility_functions/",
			"url": "https://tristinb.github.io/blog/llm_utility_functions/",
			"title": "LLMs represent a win for utility theory",
			"content_html": "<p>Our political-economic system emerges from complex interactions among humans and firms. Since the 1970s, economists have mostly agreed that we cannot understand the system as a whole without some model of the individuals within that system. Both neoclassical and behavioral economists model these individuals as if they maximize a utility function. <a href=\"https://yalebooks.yale.edu/book/9780300283327/making-sense-of-chaos/\">Complexity economists</a> and <a href=\"https://global.oup.com/academic/product/simple-heuristics-that-make-us-smart-9780195143812\">psychologists</a> argue that instead we should model humans as following simple rules, or heuristics. They note that any realistic utility function would be extremely complex, context dependent and different across individuals, making the whole concept impractical. But the success of LLMs, like ChatGPT, shows that systems can, in fact, learn complicated, context-dependent utility functions that are tailorable to individual preferences, thereby supporting the utility function view. The rest of this post shows how utility maximization drives the LLMs we use today.</p>\n<p>LLMs go through various training phases, the final of which, post-training, allows us to ask the model simple questions and receive natural-sounding responses. One post-training step, reinforcement learning from human feedback (RLHF), or with AI feedback (RLAIF), seeks to encode human stylistic and content preferences into the LLM.[^RLHF_BOOK] RLHF works by feeding a prompt to a language model and then having it output several different completions to the prompt. A labeler then notes which completion it prefers. With this labeled dataset, another LLM then learns to predict the labelers' preferences over the completions. Using reinforcement learning with the reward model, the base LLM learns to fine tune its responses.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/llm_utility_functions/\" id=\"fnref1\">[1]</a></sup></p>\n<p>Economists follow a similar formula when they try to estimate utility functions. They observe consumers choosing between various affordable items and then note which was purchased, or preferred. From data on many such transactions economists then fit a model, much smaller than an LLM, to estimate a utility function. Although focusing on surveys rather than behavior, Daniel Kahneman and Amos Tversky's experiments asked subjects questions such as whether they would prefer a coin flip that paid $120 for heads and nothing for tails versus a guaranteed $50. From these surveys they estimated utility functions that showed humans take larger risks to avoid losses than they would to make a similar-sized gain. This research won the Nobel prize.</p>\n<p>Note the similarity between RLHF and Kahneman and Tversky's experiments: both methods first ask a human responder to label which of two outcomes they prefer, then estimate a utility function from this data. <a href=\"https://arxiv.org/abs/2402.01306\">Ethayarajh et al</a> dig into this connection, arguing that the best performing models implicitly use utility functions similar to those proposed by Kahneman and Tversky. They propose reward models directly based on Kahneman and Tversky-inspired utility functions.</p>\n<p>Reward models show we can learn utility functions, but what about the problem of them changing across contexts and people? LLM-based reward models easily deal with even slight contextual shifts. During pretraining, the model learns that wine relates more closely with vineyard-related vocabulary than beer does. RLHF reinforces these relationships, as the model learns how the context of a prompt impacts the completions that labelers prefer.</p>\n<p>Incorporating diverse human preferences presents a larger challenge. Training on just one reward model assumes we all have the same preferences. But even data labelers have different preferences, with different groups producing reward models with different predictions. Taking advantage of this variation in reward models, researchers recently released an <a href=\"https://arxiv.org/abs/2409.20296\">open source dataset</a> to build and evaluate new methods to build personalized LLMs. Companies like Netflix, Meta, and Amazon profited massively from personalized content. Doing the same with LLMs will likely drive similarly massive profits. Therefore, this problem is unlikely to persist.</p>\n<p>RLHF's success shows that we can use data to estimate flexible utility functions that account for diverse contexts and preferences. Therefore, economists and others modeling complex systems can avoid encoding long lists of heuristics into their agents' behavior. Instead, they can supply data from which agents learn utility functions. Simulations of these more realistic agents interacting will teach us new lessons about how these complex adaptive systems evolve.</p>\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/llm_utility_functions/\">#</a></h2>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>Direct policy optimization, part of the broader family of direct alignment algorithms, doesn't explicitly train a reward model or use reinforcement learning to update the LLM. But these are still done implicitly. The models still optimize the Bradley-Terry preference model. <a href=\"https://tristinb.github.io/blog/llm_utility_functions/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2025-06-05T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/innovation_collective_intelligence/",
			"url": "https://tristinb.github.io/blog/innovation_collective_intelligence/",
			"title": "Innovation, knowledge workers and collective intelligence",
			"content_html": "<p>Fiverr's CEO, Micha Kaufman, recently told his employees that <a href=\"https://www.entrepreneur.com/business-news/fiverr-ceo-says-ai-will-take-your-job-heres-what-to-do/491198\">no job is safe</a> from AI. OpenAI's founder Sam Altman predicted that AI would soon allow a one-person team to build a company worth $1 billion. These statements paint a future of business as one of super-intelligent machines driving innovation. But John Kay's new book <em>The Corporation in the 21st Century</em> draws inspiration from complexity science to suggest these views deeply misunderstand how innovation works.</p>\n<p>Kay argues that workers may have resembled cogs in the 20th century, but today's giants like Apple and Google rely more on workers' collective intelligence throughout the product development cycle. While employees on the factory floor were often given specific <em>tasks</em> to complete, today's knowledge workers are typically given complex <em>problems</em> to solve.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/innovation_collective_intelligence/\" id=\"fnref1\">[1]</a></sup> Innovation arises from the interaction of each of these individual workers.</p>\n<p>Much like a flock of starlings produces patterns you could never predict by analyzing a single bird, or how consciousness somehow arises from a network of firing neurons, the modern company arises from this complex interaction among workers. Like the flock of starlings, the corporation is qualitatively different from the sum of its parts. It is not reducible to any single employee, super-genius or otherwise. In the words of complexity science, the modern corporation is <em>emergent</em>. Kay argues that innovation is emergent and cannot happen without collective intelligence. Nobody within Airbus, for example, knows every aspect of the double-decker A380 nor could someone single-handedly direct a team to produce one. Similarly, teams behind UX, design, engineering, supply chain management and more were all vital to the iPhone's success.</p>\n<p>But perhaps one person with AI could build the next generation jumbo jet? Although current AI systems have massive knowledge bases to draw upon, Meta's Chief AI Scientist Yann Lecun argues that they cannot innovate because they don't truly understand the problem they are trying to solve. The best applications of AI systems, so far, seem to be with coding and homework. Notice that these applications have either exact or closely analogous known solutions that the system can quickly look up and that humans-in-the-loop can verify. These types of applications are useful, but they are solving tasks whereas true innovation stems from solving problems.</p>\n<p>Kay never attempts to define any sort of critical number of humans interacting that would be necessary for innovation, as this would surely differ across firms and industries. But perhaps the task-problem dichotomy can provide a good heuristic. History has shown that tasks, easily verifiable with known solutions, are often outsourced and automated. But Kay argues that innovation requires an interaction among several problem-solving humans. Any minimum number of employees is likely related to the number of problems to be solved. Corporate leaders who assume that their knowledge plus AI can do everything and too aggressively downsize are likely to end up on Kay's long list of companies now dead because they failed to innovate.</p>\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/innovation_collective_intelligence/\">#</a></h2>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>Jeremy Utley and Perry Klebahn's <em>Ideaflow</em> defines a task as being verifiable and with a known solution, whereas a problem is one that nobody knows how to solve. <a href=\"https://tristinb.github.io/blog/innovation_collective_intelligence/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2025-05-09T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/ai_seo_political_science/",
			"url": "https://tristinb.github.io/blog/ai_seo_political_science/",
			"title": "What political science teaches us about AI SEO",
			"content_html": "<p>Imagine you ask somebody at a CrossFit gym what they eat after a workout. They recommend boiled ground beef. Now imagine, you ask ChatGPT for the best diapers. According to <a href=\"https://www.theinformation.com/articles/ai-search-new-arms-race-retailers\">The Information</a>, you will be recommended Coterie. As SEO evolves to cater to AI search, companies are working to understand how to get these bots to recommend their particular products. The above article mentions several methods companies now employ to better understand AI search. These methods closely resemble those that political scientists have long-used to understand belief formation.</p>\n<p>Media diets impact both people and chatbots. On the people side, research going back to at least Zaller's <em>Nature and Origins of Mass Opinion</em> notes that political attitudes are largely a function of what someone consumes from the media. Supporting this idea, researchers recently ran an experiment where they paid <a href=\"https://www.journals.uchicago.edu/doi/10.1086/730725\">Fox News viewers to watch CNN for a month</a>. After a month of watching CNN, these users had more moderate political beliefs compared to a control group. Just as the source matters for political -- or nutritional -- beliefs, companies are applying similar thinking to AI systems. The Information article above notes that companies closely monitor what sources LLMs cite in their answers. For example, startups like <a href=\"https://www.tryprofound.com/\">Profound</a> use several variants of a search and count what sources are cited. Similarly, the article notes that marketers are posting more content on Reddit, which they believe is a hotbed for raw content that will eventually be featured in AI search results.</p>\n<p>But people don't uncritically parrot <em>all</em> of the news they come across. People, and LLMs, still need to be persuaded. Both <a href=\"https://www.anthropic.com/research/mapping-mind-language-model\">LLM creators</a> and new companies are working to understand what &quot;persuades&quot; these bots to respond as they do. This can also benefit from political science research. A recent paper studying the impact of <a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12649\">a personal attack in a campaign advertisement</a> noted that you can't simply A/B test one version of an ad that contained an attack and another that does not. For instance, imagine a policy that induced anger among many respondents. Because this policy makes people angry, it is more amenable to an attack ad. Comparing the attack ad to another version of the same ad minus the attack won't accurately measure the causal impact of the attack on a viewer's attitude because both the attack and the response to the ad is confounded by the anger-inducing policy. This type of political science research shows us that A/B testing with AI search has subtle differences from A/B testing typically used to evaluate marketing campaigns.</p>\n<p>As AI search engines become more prevalent, marketers could greatly benefit from adopting social science tools. Content may need to be hosted on platforms that LLMs are likely to scrape and A/B testing will need to account for confounders in the text. Political scientists have spent decades studying and measuring opinion formation. In the process they have built a large toolbox that can help navigate AI search.</p>\n",
			"date_published": "2025-04-01T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/absence_of_evidence/",
			"url": "https://tristinb.github.io/blog/absence_of_evidence/",
			"title": "When absence of evidence is evidence of absence",
			"content_html": "<p>Journalists from various outlets have spent the last few weeks pouring over more than two thousand newly declassified documents on John F. Kennedy's assassination. So far, no new evidence shows that anybody other than Lee Harvey Oswald was involved. We shouldn't be surprised -- more than 60 years of &quot;no evidence&quot; provides strong evidence for no government conspiracy. Often times, absence of evidence IS evidence of absence.</p>\n<p>We can show this with simple math, particularly with Bayes' rule. Our goal is to estimate probability that the government killed JFK. To be concrete, let's define our evidence as 60 years with no conviction. As background information, we can include everything else regarding our belief of the government's guilt, from how nefarious the government is, to motivations etc.</p>\n<p>From this information, all we need for our calculation is the following:</p>\n<ol>\n<li>\n<p>Our prior, or our belief that the government killed Kennedy. This is all of our background information <em>other</em> than 60+ years of no convictions.</p>\n</li>\n<li>\n<p>The likelihood of observing the evidence given the hypothesis is true. That is assuming the government did kill Kennedy, what is the probability we would see 60+ years without a conviction?</p>\n</li>\n<li>\n<p>The likelihood of observing the evidence given the hypothesis is false. That is, assuming the government had nothing to do with the assassination, what is the probability we wouldn't see a government official convicted?<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/absence_of_evidence/\" id=\"fnref1\">[1]</a></sup></p>\n</li>\n</ol>\n<p>Now let's put these numbers into the table below. For (1) let's assume ignorance regarding the government killing Kennedy -- all our background information washes out -- and put our prior at 50-50.</p>\n<p>For (2) we start by assuming the government killed Kennedy. Given this assumption, what's the probability we would see no conviction after 60 years? Let's suppose the CIA is good at covering things up, but not perfect -- plenty of evidence exists on things like Bay of Pigs, Iran, Guatemala, etc. Furthermore, there have been several government investigations and independent reports. Some politician surely would have benefited from a smoking gun showing the government's involvement and more. In other words, many people have been looking for evidence, if it existed it's likely someone would have found it. Yet it is absent. But let's be conservative and put the probability of a JFK-murdering government <em>not</em> having a anyone convicted after 60+ years at 10 percent.</p>\n<p>Finally, (3) asks us to consider the probability of no conviction given the government was <em>not</em> involved. This answer is straightforward -- if the government wasn't involved, we wouldn't expect to see much. We should provide an outside chance of someone planting evidence for fame and political points, but that is about it if we assume the government's innocent. So let's call this 99 percent.</p>\n<p>The table below uses these probabilities to calculate our posterior belief that the government killed JFK.</p>\n<table>\n<tr><th>Data</th><th>Description</th><th>Value</th></tr>\n<tr><td>Prior</td><td>How probable is the hypothesis</td><td><input type=\"number\" id=\"prior\" min=\"0\" max=\"1\" value=\".5\" step=\".05\" onchange=\"calcProb()\"></td></tr>\n<tr><td>Prob(data | h=True)</td><td>How probable is the data if the hypothesis is true?</td><td><input type=\"number\" id=\"lk_true\" min=\"0\" max=\"1\" value=\".1\" step=\".05\" onchange=\"calcProb()\"></td></tr>\n<tr><td>Prob(data | h=false)</td><td>How probable is the data if the hypothesis is false?</td><td><input type=\"number\" id=\"lk_false\" min=\"0\" max=\"1\" value=\".99\" step=\".05\" onchange=\"calcProb()\"></td></tr>\n<tr style=\"font-weight: bold;\"><td>Prob(h | h=true)</td><td>How probable is our hypothesis given the data?</td><td id=\"posterior\"> 0.0917</td></tr>\n</table>\n<p>The absence of a conviction over 60 years brings our prior belief of the government's guilt down from 50 percent to about 9 percent. You can see most of this shift in the ratio of (2) to (3), or the absence of evidence given the government being guilty compared with the absence of evidence given the government being innocent. The large number of people searching for evidence, yet finding none after 60+ years, leads us to put a low probability p(data | h=true). Conversely, an innocent government is consistent with us not finding much evidence, leading to a high probability on p(data | h=false). Therefore, the absence of evidence provides strong evidence that the government had nothing to do with the assassination, enough to bring our 50 percent belief down to 9 percent.</p>\n<p>But absence of evidence may also mean nothing. For example, suppose I am searching for buried treasure in the mountains of Idaho with little more than a Reddit thread to guide me. Here the probability of me not finding the treasure, given my search material is high. By toggling the second row of the table above, you will see that the lack of treasure found on my search doesn't say much about whether the treasure exists.</p>\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/absence_of_evidence/\">#</a></h2>\n<script>\n\nconst calcProb = () => {\n    const prior = parseFloat(document.getElementById('prior').value);\n    const lk_true = parseFloat(document.getElementById('lk_true').value);\n    const lk_false = parseFloat(document.getElementById('lk_false').value);\n    \n    const num = prior*lk_true\n    const denom = prior*lk_true + (1-prior)*lk_false\n    if(denom==0){\n        document.getElementById('posterior').textContent = 0\n    }\n    else {\n    const prob = num/denom\n    document.getElementById('posterior').textContent = parseFloat(prob.toFixed(2))\n    \n    }\n    \n\n}\n\n</script><hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>Typically with Bayes rule the third factor is the probability of the evidence. But in this case that would just be the prior (1) times the likelihood (2) plus one minus the prior times (3). <a href=\"https://tristinb.github.io/blog/absence_of_evidence/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2025-03-24T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/text_as_confounder/",
			"url": "https://tristinb.github.io/blog/text_as_confounder/",
			"title": "How Text Data Can Improve (or Worsen) Business Decisions",
			"content_html": "<p>Marketing, sales, and product teams often need to answer questions such as &quot;does price impact customer satisfaction scores?&quot; However, these types of questions are difficult to answer directly because other factors, such as item quality, may cause an item to be both more expensive and more highly rated. In other words, variables like quality may confound the relationship between price and satisfaction.</p>\n<p>Fortunately, these teams often have reams of text data from sources such as outreach campaigns, social media posts, and open-ended reviews from which they can extract confounding variables, like quality. This post shows how we can use text data to improve our inferences about the relationship between important variables. But it also shows that if we aren't careful with our analysis, we may end up making our estimates even worse.</p>\n<h2 id=\"the-basic-problem\" tabindex=\"-1\">The basic problem <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/text_as_confounder/\">#</a></h2>\n<p>To motivate the post, assume we want to infer the impact of price on a customer rating. In addition to the price and the rating, we also have the customer's open-ended review. The table below provides an example piece of data:</p>\n<h3 id=\"example-review\" tabindex=\"-1\">Example Review <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/text_as_confounder/\">#</a></h3>\n<p><strong>Rating</strong>: ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ (4/5)</p>\n<p><strong>Price</strong>: $$$$$ (5/5)</p>\n<p><strong>Review</strong></p>\n<p><em>The grass-fed Wagyu ribeye, with perfect marbling, was fantastic. Although it was expensive, like everything else these days, the experience was amazing.</em></p>\n<p>Phrases like &quot;Perfect marbling&quot; and &quot;grass-fed ribeye&quot; provide information regarding quality that we can extract and use to adjust for confounding. But the review also contains information about many other concepts. The table below provides an incomplete set of the concepts we could extract, along with the relationship these concepts have to price and the rating.</p>\n<h2 id=\"concepts-from-review\" tabindex=\"-1\">Concepts from review <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/text_as_confounder/\">#</a></h2>\n<table>\n<thead>\n<tr>\n<th>Text Element</th>\n<th>Extractable Concept</th>\n<th style=\"text-align:center\">Impacts Price</th>\n<th style=\"text-align:center\">Impacted by Price</th>\n<th style=\"text-align:center\">Impacts Rating</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>grass-fed Wagyu ribeye, with perfect marbling</td>\n<td>Quality</td>\n<td style=\"text-align:center\">‚úì</td>\n<td style=\"text-align:center\">‚úó</td>\n<td style=\"text-align:center\">‚úì</td>\n</tr>\n<tr>\n<td>fantastic.. the experience was amazing... expensive</td>\n<td>Overall Sentiment</td>\n<td style=\"text-align:center\">‚úó</td>\n<td style=\"text-align:center\">‚úì</td>\n<td style=\"text-align:center\">‚úì</td>\n</tr>\n<tr>\n<td>expensive, like everything else these days</td>\n<td>Economic inflation</td>\n<td style=\"text-align:center\">‚úì</td>\n<td style=\"text-align:center\">‚úó</td>\n<td style=\"text-align:center\">‚úó</td>\n</tr>\n</tbody>\n</table>\n<p><em>Legend: ‚úì = Yes, ‚úó = No</em></p>\n<p>The table shows that in addition to quality we can also extract information on the review's overall sentiment as well as a macroeconomic concept, economic inflation. We can also see that overall sentiment is, in part, caused by price and sentiment also impacts the rating. Economic inflation impacts the price, but it is only through price that it impacts the rating.</p>\n<p>If we include features that capture sentiment and inflation, without making other adjustments, we can end up with even more biased estimates of the relationship between price and the rating than if we just ignored the text data completely.</p>\n<h2 id=\"how-we-can-use-text-to-improve-not-worsen-our-inferences\" tabindex=\"-1\">How we can use text to improve, not worsen, our inferences <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/text_as_confounder/\">#</a></h2>\n<p>We have two standard approaches to extract information from text to include in our model. The first approach is to predefine a concept, such as quality, and then instruct an LLM (or human labelers) to annotate whether the concept exists in the text and, if it exists, to provide some score regarding the strength of the concept. These scores are typically coarse and somewhat arbitrary. For instance, quality would be defined as something like as &quot;high, medium, low&quot;.</p>\n<p>The second approach is a bit more involved and is described in the figure below.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/text_as_confounder/\" id=\"fnref1\">[1]</a></sup> This approach has the benefit of automatically extracting concepts from the text as well as providing more precise scores -- real numbers instead of a label like &quot;high&quot;.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/yDvbIM_ViJ-1306.avif 1306w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/yDvbIM_ViJ-1306.webp 1306w\"><img alt=\"Transforming Text to Features\" loading=\"lazy\" decoding=\"async\" class=\"responsive-image\" style=\"max-width: 100%; height: auto;\" src=\"https://tristinb.github.io/img/yDvbIM_ViJ-1306.png\" width=\"1306\" height=\"1010\"></picture></p>\n<p>To walk through the approach above, we start with an embedding model to transform the text-review to a vector of numbers. Then, since this vector will be large -- OpenAI's <code>text-embedding-3-small</code> is 1,536 dimensions -- we typically apply some algorithm to reduce the vector space down to something smaller. For our purposes, lets suppose we were able to reduce the embedding space down to 3 dimensions. Unlike in the first approach, where the text would be classified as something like <code>high</code> here we would get different numbers for each observation. One observation may get [0.2, -.5, 1.2], while another gets [.1, .5, -2]. This is much more fine grained than a label like <code>high</code> and we don't have to explicitly instruct the model to search for something like &quot;quality&quot;. For these reasons, the second approach is much more attractive than the first.</p>\n<p>But the drawback of this approach is that we don't actually know what concepts we extract from the text -- dimensionality reduction doesn't come with a label -- nor how these concepts are related to the variables we care about. But for clarity, let's assume we do know what these concepts are. The figure below assumes that we extract &quot;sentiment&quot;, &quot;inflation&quot; and &quot;quality&quot; from the text. It then shows how these concepts relate to price and quality.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/M9kNHEC5Fi-1398.avif 1398w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/M9kNHEC5Fi-1398.webp 1398w\"><img alt=\"Estimating Price and Rating\" loading=\"lazy\" decoding=\"async\" class=\"responsive-image\" style=\"max-width: 100%; height: auto;\" src=\"https://tristinb.github.io/img/M9kNHEC5Fi-1398.png\" width=\"1398\" height=\"684\"></picture></p>\n<p>If we simply include these values in our model, there are at least <a href=\"https://web.mit.edu/~rnielsen/www/textmatching.pdf\">two cases</a> where we would end up with worse estimates than if we ignored the text altogether. These areas are post-treatment bias, which would arise from using sentiment, and bias amplification, which would arise from using economic inflation.</p>\n<h3 id=\"post-treatment-bias\" tabindex=\"-1\">Post-treatment bias <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/text_as_confounder/\">#</a></h3>\n<p>Suppose we included overall sentiment in our model. From Figure 2 above, we can see that price only impacts the rating through its impact on the customer's overall sentiment. Since price's impact on the rating is fully absorbed into overall sentiment, including this concept in our model would lead us to infer -- incorrectly -- that price is unrelated to the rating.</p>\n<p>Therefore, if our process of transforming raw text leads to concepts that enter the model in a way that cuts between the variable we care about and the outcome, we need to be careful to <em>not</em> include it.</p>\n<h3 id=\"bias-amplification\" tabindex=\"-1\">Bias amplification <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/text_as_confounder/\">#</a></h3>\n<p>The second issue is more nuanced, and arises when we include a variable that is strongly related to our predictor variable and only weakly, or not at all, related to the outcome variable. There also needs to be some unobserved confounding variable. Imagine a version of Figure 2 that only included &quot;inflation&quot; and &quot;quality&quot; along with &quot;price&quot; and &quot;rating&quot;.</p>\n<p>Since inflation and quality both impact price, including both in the model makes them statistically dependent. This leads inflation to have a non-causal, confounded, path to the rating. Since inflation is now confounded, our estimates for price will be even more confounded than if we had just left inflation out all together. This concept is known as bias amplification and although it receives much less attention than issues such as post-treatment bias and confounding, it can similarly bias results. As (<a href=\"https://arxiv.org/abs/1203.3503\">Pearl (2010)</a>) notes, bias amplification is especially likely when estimating propensity scores, which is common in analyses using text.</p>\n<h3 id=\"what-to-do\" tabindex=\"-1\">What to do <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/text_as_confounder/\">#</a></h3>\n<p>To use text to improve, and not worsen, our inferences we need to reduce the dimensions of the embeddings jointly with the model that we want to estimate. Using figure 2 as an example, we can to extract concepts that align with the confounder, instrumental variable and post-treatment variables. By extracting only these concepts from the review we could then estimate the correct model for our purposes.</p>\n<p>But if we aren't careful of how the concepts we extract from text fit into the overall model we are trying to estimate, we may end up with something even worse than if we had ignored the text data in the first place.</p>\n<h2 id=\"conclusion\" tabindex=\"-1\">Conclusion <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/text_as_confounder/\">#</a></h2>\n<p>Companies are sitting on mountains of text data. By appropriately incorporating it into our models, we can answer important questions for teams across the organization. But failing to account for how the concepts we extract from the text data relate to the question may lead to even worse inferences and worse decisions.</p>\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/text_as_confounder/\">#</a></h2>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>Another version of this approach is to use the text embedding to estimate a propensity score (<a href=\"https://arxiv.org/abs/2009.09961\">Weld et al. 2020</a>). But notice that concepts such as inflation and sentiment will be highly predictive of the price and may look like attractive predictors. Including these variables in our propensity score model will cause the same issues as that outlined here. Using these embeddings directly give us no sense of where the features fit into our causal model. <a href=\"https://tristinb.github.io/blog/text_as_confounder/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2025-03-04T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/shap_values/",
			"url": "https://tristinb.github.io/blog/shap_values/",
			"title": "Shapley Values for Interpretable ML",
			"content_html": "<p>With machine learning (ML) impacting more and more of our daily lives interpretable ML is becoming more critical. Shapley values offer a method to explain why models make their predictions. But although Shapley values may shed some light onto an ML model's behavior, these values themselves lack an intuitive interpretation. This post goes over the game theory foundation of Shapley values, then shows how ML approaches are built on this foundation. It then shows why Shapley values tell us much less about our data and models than we may have hoped.</p>\n<h2 id=\"shapley-values\" tabindex=\"-1\">Shapley values <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/shap_values/\">#</a></h2>\n<p>Shapley values applied have their origin in cooperative game theory. Two driving questions of cooperative game theory are 1) what coalitions will form and 2) how will the coalitions divide their winnings.</p>\n<p>We can show this through a simple example of voting in a 100 member legislature that needs a simple majority to pass a rule. Suppose this legislature has four voting parties that always vote in unison. Party A has 40 members, B has 30 members, C and D each have 15 members. If parties come together to get a majority, they win $100 to split; those outside the coalition win $0. If A is in a winning coalition, how much of the $100 should they get? Party A's Shapley value would be a fair cut of the $100.</p>\n<p>With a little bit of abstraction, let <em>i</em> represent any of the parties A, B, C, D. The intuition for calculating the Shapley value for party <em>i</em> goes as follows. First, the calculation only considers the grand coalition, or the coalition involving all 4 players. Then, we consider all possible orderings, or permutations, of this coalition. Each of these orderings has a point where party <em>i</em> enters the coalition -- 1st, 2nd, 3rd, or 4th in our example. With each of these orderings, we take difference in the coalition's value right before <em>i</em> entered and right after <em>i</em> entered. This difference tells us how much value <em>i</em> brought to that particular ordering. If we do this across all possible orderings and then take the average of these values, we will have player <em>i</em>'s Shapley value.</p>\n<p>As an example, the table below shows how we can calculate the Shapley value for party A. Recall A has 40 votes, B has 30, while C and D each have 15 votes.</p>\n<p><strong>Different Coalition Orderings for Party A</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:right\">Position in the ordering</th>\n<th style=\"text-align:right\">Example Coalitions</th>\n<th style=\"text-align:right\">Value Before A</th>\n<th style=\"text-align:right\">Value with A</th>\n<th style=\"text-align:right\">Marginal Contribution</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:right\">1</td>\n<td style=\"text-align:right\">{A,B,C,D}</td>\n<td style=\"text-align:right\">0</td>\n<td style=\"text-align:right\">0</td>\n<td style=\"text-align:right\">0</td>\n</tr>\n<tr>\n<td style=\"text-align:right\">2</td>\n<td style=\"text-align:right\">{B,A,C,D}, {C,A,B,D}</td>\n<td style=\"text-align:right\">0</td>\n<td style=\"text-align:right\">100</td>\n<td style=\"text-align:right\">100</td>\n</tr>\n<tr>\n<td style=\"text-align:right\">3</td>\n<td style=\"text-align:right\">{B,C,A,D}, {C,B,A,D}</td>\n<td style=\"text-align:right\">0</td>\n<td style=\"text-align:right\">100</td>\n<td style=\"text-align:right\">100</td>\n</tr>\n<tr>\n<td style=\"text-align:right\">4</td>\n<td style=\"text-align:right\">{B,C,D,A}, {C,B,D,A}</td>\n<td style=\"text-align:right\">100</td>\n<td style=\"text-align:right\">100</td>\n<td style=\"text-align:right\">0</td>\n</tr>\n</tbody>\n</table>\n<p>This table only shows some of the possible orderings. In total number of permutations here is 4!=24, with 6 possibilities for every position that A can enter. In 12 of these A's marginal contribution is 100; in 12 it is 0. Therefore, A's average marginal contribution across all coalitions, or its Shapley value is 50.</p>\n<p>If we run Shapley values for other players we will notice that they are 16.67. This may seem odd: B has 30 votes, C and D each have 15. B could argue that they brought twice as much to the table as either C or D so they should be entitled to twice the reward. But without A, B would still need both C and D to get to 51 votes. In other words, despite having twice the number of votes C has, B can never add value where C can't. In the terms of game theory, B and C here are <em>interchangable</em> as they were both equally important to any coalition.</p>\n<p>These values don't directly line up to the number of votes each party provides. Party A's Shapley value is 50, although they bring 40 votes. As the table above showed, across all possible coalitions, Party A increased the grand coalition's payoff by 50, on average -- this is the amount of value, not votes, that party A brings. Similarly, Party B and C have a different number of votes, but the same Shapley value. This is, again, because both parties contributed the same amount on average to the full coalition's payoff. We know that parties B and C have a different number of votes, but we can't infer that from the Shapley values alone.</p>\n<p>Similarly, If we remove A from the grand coalition, the payoff isn't 100 minus player A's Shapley value of 50. Instead, since the number of votes without A is 60, the coalition will still get 100. All the Shapley values really tell us here is that Party A is the most important member, while the other three are equally important.</p>\n<h2 id=\"shapley-values-in-machine-learning\" tabindex=\"-1\">Shapley values in machine learning <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/shap_values/\">#</a></h2>\n<p>Machine learning models take in a set of inputs (features), calculate a bunch of interactions between them and then output a prediction. Because of these interactions' complexity, these models are often called black-boxes. To understand why these black-boxes made their predictions, practitioners commonly use Shapley values.</p>\n<p>Making the leap frm game theory to machine learning will be easier if we clarify a few definitions.</p>\n<ol>\n<li><strong>The Coalition</strong>: For ML, the coalition is defined as a single observation of input features. You can think of this as a row in a data frame.</li>\n<li><strong>The Payoff</strong>: The coalition's payoff is defined as the difference between the model's prediction for the observed row (i.e. the coalition) and the average model prediction across all observations.</li>\n<li><strong>The Shapley value</strong>: for each feature in each row is an estimate of how important that feature was for the deviation from the average prediction. A positive value means the feature pushed the prediction up, while a negative means it pushed it down.</li>\n</ol>\n<p>To clarify the above definitions, if the a model's average prediction is 0.55 and the model's prediction for a particular row is .65, then the payoff for that row is 0.1. A Shapley value is then given to each feature in the row such that the sum of the values is to 0.1.</p>\n<p>But now we have the problem of actually estimating this value from data. In our example above, when we calculated the Shapley value for party A, we had to consider all possible coalitions. In that example, the coalitions either offered all of their votes or zero votes, and we knew what would happen without them.</p>\n<p>We generally don't know how to set the other values, and zero often makes little sense.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/shap_values/\" id=\"fnref1\">[1]</a></sup> To overcome this, algorithms create synthetic -- fake -- observations. Assume we are calculating the Shapley value for Party A from the example above. But assume we have only data for each coalition over time, where the number of votes changes by year. A dataset could  look like the following:</p>\n<p><strong>Party Votes by Year</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:right\">Year</th>\n<th style=\"text-align:right\">A</th>\n<th style=\"text-align:right\">B</th>\n<th style=\"text-align:right\">C</th>\n<th style=\"text-align:right\">D</th>\n<th style=\"text-align:right\">majority</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:right\">1</td>\n<td style=\"text-align:right\">40</td>\n<td style=\"text-align:right\">30</td>\n<td style=\"text-align:right\">15</td>\n<td style=\"text-align:right\">15</td>\n<td style=\"text-align:right\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:right\">2</td>\n<td style=\"text-align:right\">25</td>\n<td style=\"text-align:right\">25</td>\n<td style=\"text-align:right\">25</td>\n<td style=\"text-align:right\">25</td>\n<td style=\"text-align:right\">1</td>\n</tr>\n</tbody>\n</table>\n<p>We are going to try to estimate A's Shapley value in the first row. Suppose we are measuring the marginal effect of A entering the coalition after B. First, we take a random row from the the rest of the dataset. Let's assume that sample is row 2. We then need to create two synthetic rows of data and compare their differences in model output.</p>\n<p>The first synthetic row includes B and A from row 1 with C and D's values from row 2. The second synthetic row uses B's value from row 1 with the rest of the values from row 2. The table below shows these two examples.</p>\n<p><strong>Synthetic Data</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:right\">Coalition</th>\n<th style=\"text-align:right\">A</th>\n<th style=\"text-align:right\">B</th>\n<th style=\"text-align:right\">C</th>\n<th style=\"text-align:right\">D</th>\n<th style=\"text-align:right\">majority</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:right\">A After B</td>\n<td style=\"text-align:right\">40</td>\n<td style=\"text-align:right\">30</td>\n<td style=\"text-align:right\">25</td>\n<td style=\"text-align:right\">25</td>\n<td style=\"text-align:right\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:right\">B Only</td>\n<td style=\"text-align:right\">25</td>\n<td style=\"text-align:right\">30</td>\n<td style=\"text-align:right\">25</td>\n<td style=\"text-align:right\">25</td>\n<td style=\"text-align:right\">1</td>\n</tr>\n</tbody>\n</table>\n<p>We would then pass each of these rows through our model and calculate the difference between them to get the marginal impact of A. We then repeat this many times to get an estimate for A and then do this again for all the Shapley values.</p>\n<p>But these synthetic values are often quite different than the data used to train the model. Notice that the sum of the votes in both rows exceeds 100. A model trained on real data would never see this in a 100 member legislature. However, ML models will likely extrapolate anyway and come up with some prediction, despite it not being based in reality. This prediction is then sensitive to how the model extrapolates. Taking advantage of synthetic examples being quite different than the observed data <a href=\"https://arxiv.org/abs/1911.02508\">Slack et al (2019)</a> built a model that heavily incorporated race and gender to make predictions, but by exploiting synthetic examples were able to output Shapley values for these features that suggested the model didn't find them to be important.</p>\n<p>Therefore, since it isn't clear how to turn &quot;off&quot; a feature -- as we could do in our game theory example above -- most methods sample from the other rows of data. But these synthetic rows are often very different from the underlying data, making it difficult to accurately calculating the marginal impact of a feature.</p>\n<h2 id=\"can-we-take-action-based-on-shapley-values\" tabindex=\"-1\">Can we take action based on Shapley Values? <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/shap_values/\">#</a></h2>\n<p>Ultimately, Shapley values are typically used for predictive models, which seek to exploit correlations. Because of the model assumptions and the way the data is typically collected, they don't tell us anything about what would happen if we actually intervened and changed a variable. This isn't really the goal of the method. However, explaining a model typically asks what would happen if we changed a feature to a particular value.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/shap_values/\" id=\"fnref2\">[2]</a></sup> But Shapley values don't tell us anything about this.</p>\n<p>Going back to the very first example, we know that if we removed A from the coalition, we would lose 40 votes. But the Shapley value of 50 doesn't suggest that. Furthermore, if we removed B or C we would lose 30 and 15 votes, respectively, but both of these parties have the same Shapley value. In other words, Shapley values don't provide much guidance on what would happen if we intervened in a system. This fundamental problem exists on top of the computational associated with actually calculating them.</p>\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/shap_values/\">#</a></h2>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>Values are sometimes &quot;turned off&quot; by setting them to their mean. But this results in the same issues as the examples used to compute Shapley values. <a href=\"https://tristinb.github.io/blog/shap_values/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n<li id=\"fn2\" class=\"footnote-item\"><p>There is a huge amount of literature on this. The most accessible starting point is probably (<a href=\"https://www.amazon.com/Book-Why-Science-Cause-Effect/dp/046509760X\">Pearl and Mackenzie 2018</a>) <a href=\"https://tristinb.github.io/blog/shap_values/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2024-12-09T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/rafah_gaza_war/",
			"url": "https://tristinb.github.io/blog/rafah_gaza_war/",
			"title": "Can Biden Make Bibi Balk?",
			"content_html": "<p>In the ongoing Israel-Gaza war, Biden recently told the press that he would cut off certain types of military aid to Israel if Netanyahu invaded Rafah. Netanyahu and his most hawkish advisors responded that Israel will do what it deems necessary to defend itself. This post applies a simple model to the current situation to better understand Biden's options and the dynamics in the dispute between Biden and Netanyahu.</p>\n<h2 id=\"model\" tabindex=\"-1\">Model <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/rafah_gaza_war/\">#</a></h2>\n<p>We can model Israel's decision to invade Rafah as a Bayesian game. A key feature of Bayesian games is that a player can be a certain &quot;type&quot;. For example, they can be sane or crazy, red or green, strong or weak, any number between 0 and 100 etc. In the model, players don't know the others' types, but they do know the probability distribution over the type. In this setup, we have two players: Biden (B) and Netanyahu (N). Biden's type is either strong or weak. Biden knows his type, but Netanyahu only knows the probability that Biden is either strong or weak.</p>\n<p>Netanyahu can choose to either <code>Attack</code> or <code>Refrain</code>. If he chooses <code>Refrain</code>, the game ends, leaving Biden a payoff for convincing Netanyahu to refrain, <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.048ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.434ex\" height=\"1.593ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 1518 704\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(759,0)\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>R</mi><mi>B</mi></math></mjx-assistive-mml></mjx-container>, and Netanyahu a payoff for refraining, <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.048ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.726ex\" height=\"1.593ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 1647 704\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(759,0)\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>R</mi><mi>N</mi></math></mjx-assistive-mml></mjx-container>.</p>\n<p>If Netanyahu chooses to attack, he will get a payoff of <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.011ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 889 683\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></mjx-assistive-mml></mjx-container>. But if Biden chooses to Sanction Netanyahu, or to cut off military aid, that <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.011ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 889 683\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></mjx-assistive-mml></mjx-container> will come at a cost. Since that cost can be seen as coming from the US government, we assume it is the same regardless of Biden's type. If Biden chooses <code>Backdown</code> Israel won't pay a cost from the US reaction, so Netanyahu gets all of <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.011ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 889 683\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></mjx-assistive-mml></mjx-container> and Biden gets a payoff of <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.894ex\" height=\"1.593ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -694 1279 704\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(759,0)\"><path data-c=\"1D451\" d=\"M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi><mi>d</mi></math></mjx-assistive-mml></mjx-container>.</p>\n<p>The game is shown in the figure below. The left side of the tree represents the world where Biden is strong; the right side represents where Biden is weak. The dashed line means that Netanyahu, N, does not know whether he is in the world of Strong or Weak Biden.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/2Y5T0McLcY-423.avif 423w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/2Y5T0McLcY-423.webp 423w\"><img alt=\"Game Tree\" loading=\"lazy\" decoding=\"async\" class=\"responsive-image\" style=\"max-width: 100%; height: auto;\" src=\"https://tristinb.github.io/img/2Y5T0McLcY-423.png\" width=\"423\" height=\"311\"></picture></p>\n<p>You can see that the game has many undefined variables, or parameters. If they take on certain values, we can find a unique solution to the game. Here are the parameters we need to define:</p>\n<table>\n<thead>\n<th>Parameter</th><th>Description</th>\n</thead>\n<tr><td>Œ∏</td><td>Probability Biden's type is Strong</td></tr>\n<tr><td>RB</td><td>B's payoff for N refraining </td></tr>\n<tr><td>RN</td><td>N's payoff for refraining </td></tr>\n<tr><td>K</td><td>N's payoff for attacking</td></tr>\n<tr><td>cost</td><td>Cost from B's retaliation</td></tr>\n<tr><td>S_s</td><td>Payoff to strong type for sanctioning</td></tr>\n<tr><td>S_w</td><td>Payoff to weak type for sanctioning</td></tr>\n<tr><td>Bd</td><td>Payoff for backing down</td></tr>\n</table>\n<p>To find the subgame perfect Bayesian Nash equilibrium, we can start from the bottom of the tree and work our way up. First, let's start on the left, where Biden is the strong type. Since Strong Biden loves to fight, it is safe to assume his payoff for <code>Sanction</code> is larger than that for <code>Backdown</code>. Concretely, since <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.355ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.325ex\" height=\"1.95ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 1027.6 862.1\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D446\" d=\"M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(646,-150) scale(0.707)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\" style=\"stroke-width: 3;\"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow data-mjx-texclass=\"ORD\"><msub><mi>S</mi><mi>s</mi></msub></mrow></math></mjx-assistive-mml></mjx-container> is greater than <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.894ex\" height=\"1.593ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -694 1279 704\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(759,0)\"><path data-c=\"1D451\" d=\"M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi><mi>d</mi></math></mjx-assistive-mml></mjx-container> strong Biden chooses <code>Sanction</code>. Furthermore, strong Biden seeks to impose a large cost on Israel for attacking, let's assume that <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.048ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.726ex\" height=\"1.593ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 1647 704\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(759,0)\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>R</mi><mi>N</mi></math></mjx-assistive-mml></mjx-container> is greater than <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"8.732ex\" height=\"1.731ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 3859.4 765\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1111.2,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(2111.4,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(433,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(918,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1387,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\" style=\"stroke-width: 3;\"></path></g></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi><mo>‚àí</mo><mrow data-mjx-texclass=\"ORD\"><mi>c</mi><mi>o</mi><mi>s</mi><mi>t</mi></mrow></math></mjx-assistive-mml></mjx-container>. In this case, Netanyahu gets a higher payoff, and therefore chooses, <code>Refrain</code>. Putting this together, under Strong Biden we get <code>Refrain</code> as an equilibrium as long as Biden's payoff for <code>Sanction</code> is greater than the payoff for <code>Backdown</code> and <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"8.732ex\" height=\"1.731ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 3859.4 765\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1111.2,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(2111.4,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(433,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(918,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1387,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\" style=\"stroke-width: 3;\"></path></g></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi><mo>‚àí</mo><mrow data-mjx-texclass=\"ORD\"><mi>c</mi><mi>o</mi><mi>s</mi><mi>t</mi></mrow></math></mjx-assistive-mml></mjx-container> is less than the payoff for <code>Refrain</code>. If either of these fail to hold, and we will revisit the second assumption later, we will get an equilibrium where Netanyahu attacks.</p>\n<p>We can repeat this on the right hand side of the tree. Here, Weak Biden does not like conflict. Therefore, if Netanyahu attacks, Biden gets a higher payoff for <code>Backdown</code> than for <code>Sanction</code>. In the model this is expressed as <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.894ex\" height=\"1.593ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -694 1279 704\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(759,0)\"><path data-c=\"1D451\" d=\"M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi><mi>d</mi></math></mjx-assistive-mml></mjx-container> being greater than <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.72ex\" height=\"1.952ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 1202.3 862.8\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D446\" d=\"M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(646,-150) scale(0.707)\"><path data-c=\"1D464\" d=\"M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z\" style=\"stroke-width: 3;\"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow data-mjx-texclass=\"ORD\"><msub><mi>S</mi><mi>w</mi></msub></mrow></math></mjx-assistive-mml></mjx-container>. Since Weak Biden will back down, Netanyahu will attacks and can expect a payoff of <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.011ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 889 683\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></mjx-assistive-mml></mjx-container>. This is a reasonable assumption since if <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.011ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 889 683\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></mjx-assistive-mml></mjx-container> wasn't credibly better than refraining, Netanyahu wouldn't have threatened to attack in the first place. Putting this together, under Weak Biden we get an equilibrium where Netanyahu chooses <code>Attack</code> and Biden chooses <code>Backdown</code>. This is different than the equilibrium under Strong Biden. The table below shows the payoffs and Netanyahu's decisions under Biden's two types.</p>\n<table>\n<tr><th>Strong</th><th>Weak</th><th>Payoff Strong</th><th>Payoff Weak</th></tr>\n<tr><td>Refrain</td><td>Attack</td><td>Œ∏ x RN</td><td>(1-Œ∏) x K</td></tr>\n</table>\n<p>For a subgame perfect Bayesian Nash equilibrium to hold, Netanyahu will choose to <code>Refrain</code> if the expected payoff for restraining is greater than the expected payoff for attacking. In the model this is expressed as <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"19.3ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 8530.4 1000\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mo\" transform=\"translate(691.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1691.4,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(759,0)\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\" style=\"stroke-width: 3;\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(3616.2,0)\"><path data-c=\"2265\" d=\"M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4672,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mn\" transform=\"translate(5061,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5783.2,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6783.4,0)\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mo\" transform=\"translate(7252.4,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7641.4,0)\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Œ∏</mi><mo>√ó</mo><mrow data-mjx-texclass=\"ORD\"><mi>R</mi><mi>N</mi></mrow><mo>‚â•</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>‚àí</mo><mi>Œ∏</mi><mo stretchy=\"false\">)</mo><mi>K</mi></math></mjx-assistive-mml></mjx-container>. Much of this depends on <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Œ∏</mi></math></mjx-assistive-mml></mjx-container>, or Netanyahu's beliefs over Biden's type. Focusing on <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Œ∏</mi></math></mjx-assistive-mml></mjx-container>, we can simplify this expression to <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -1.238ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"11.62ex\" height=\"3.222ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -877 5136 1424.1\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mo\" transform=\"translate(746.8,0)\"><path data-c=\"2264\" d=\"M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mfrac\" transform=\"translate(1802.6,0)\"><g data-mml-node=\"mi\" transform=\"translate(1352.4,394) scale(0.707)\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mrow\" transform=\"translate(220,-370.3) scale(0.707)\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(389,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(759,0)\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\" style=\"stroke-width: 3;\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2036,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2814,0)\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3703,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\" style=\"stroke-width: 3;\"></path></g></g><rect width=\"3093.5\" height=\"60\" x=\"120\" y=\"220\"></rect></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Œ∏</mi><mo>‚â§</mo><mfrac><mi>K</mi><mrow><mo stretchy=\"false\">(</mo><mrow data-mjx-texclass=\"ORD\"><mi>R</mi><mi>N</mi></mrow><mo>+</mo><mi>K</mi><mo stretchy=\"false\">)</mo></mrow></mfrac></math></mjx-assistive-mml></mjx-container>. This equation shows that as <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.011ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 889 683\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></mjx-assistive-mml></mjx-container> -- or the payoff Netanyahu gets from invading increases -- he needs to be even more convinced Biden is the strong type in order to refrain from attacking. Conversely, as <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.048ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.726ex\" height=\"1.593ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 1647 704\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(759,0)\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>R</mi><mi>N</mi></math></mjx-assistive-mml></mjx-container>, or the payoff he gets for refraining, increases he needs to be even less convinced Biden is of the strong type in order to refrain.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/rafah_gaza_war/\" id=\"fnref1\">[1]</a></sup></p>\n<p>In order to convince Netanyahu to refrain, and avoid an invasion of Rafah, the model suggests three things Biden could do.</p>\n<p>First, Biden could increase <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.048ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.726ex\" height=\"1.593ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 1647 704\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(759,0)\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>R</mi><mi>N</mi></math></mjx-assistive-mml></mjx-container>, which is Netenyahu's payoff for refraining. He could do this, for example, by offering more security guarantees or support in the United Nations. <a href=\"https://www.axios.com/2024/04/29/netanyahu-biden-icc-arrest-warrants-war-crimes\">Protection from ICC prosecution</a> could be another way to get Netanyahu to refrain.</p>\n<p>Second, Biden could try to convince Netanyahu that he is the strong type and that he will not back down from his threats. Biden going public with these threats suggests that private pressure have failed since going public will make it harder to choose <code>Backdown</code> because his domestic audiences will find him weak. A large literature on <a href=\"https://en.wikipedia.org/wiki/Audience_cost\">Audience Costs</a> explores these dynamics in detail.</p>\n<p>Third, Biden could further escalate his threats. This would decrease the payoff Netanyahu gets by invading in the event that Biden is the strong type. In other words, Netanyahu can be relatively convinced Biden is the weak type, but still choose to refrain since the cost in the event Biden is the strong type are so large.</p>\n<p>Finally, we can revisit the assumption that strong Biden can impose sufficiently strong sanctions to make Netanyahu's payoff for refraining greater than attacking. If strong Biden cannot credibly impose high enough costs to Netanyahu in the event that he attacks, for instance because he faces too many domestic constraints, then there is no equilibrium where Netanyahu chooses to refrain.</p>\n<!-- If you are interested in further exploring the three scenarios by manipulating $K$ and $RN$, you can click the button below. -->\n<!-- <button id=\"toggle-button\" onclick=\"toggleInteraction()\">Explore Scenarios</button>\n\n<div id=\"code\"> -->\n<p>By changing the values of <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.011ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 889 683\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></mjx-assistive-mml></mjx-container>, the payoff Netanyahu gets from attacking, and <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.048ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.726ex\" height=\"1.593ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 1647 704\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(759,0)\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>R</mi><mi>N</mi></math></mjx-assistive-mml></mjx-container>, the value he gets from refraining, you can see what minimum belief Netanyahu must have over Biden being the strong type in order to refrain according to the model.</p>\n<table>\n<tr><th>Parameter</th><th>Value</th></tr>\n<tr><td>K</td><td><input type=\"number\" id=\"k\" min=\"0\" max=\"10\" value=\"5\" step=\"0.5\" style=\"width: 100%;\" onchange=\"calculateMinProb()\"></td></tr>\n<tr><td>RN</td><td><input type=\"number\" id=\"rn\" min=\"0\" max=\"10\" value=\"5\" step=\"0.5\" style=\"width: 100%;\" onchange=\"calculateMinProb()\"></td></tr>\n<tr style=\"font-weight: bold;\"><td>Œ∏</td><td id=\"theta\">0.5</td>\n</tr></table>\n<p>By increasing <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.011ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 889 683\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></mjx-assistive-mml></mjx-container>, or the value Netanyahu gets from attacking, <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Œ∏</mi></math></mjx-assistive-mml></mjx-container> will rise. This means that Netanyahu can be more certain that Biden is the strong type, yet still choose to attack since he gets such a high payoff for doing so. Conversely, increasing <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.048ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.726ex\" height=\"1.593ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 1647 704\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(759,0)\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>R</mi><mi>N</mi></math></mjx-assistive-mml></mjx-container> will decrease <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Œ∏</mi></math></mjx-assistive-mml></mjx-container>. This means that as the payoffs to refraining rise, Netanyahu can be more certain Biden is the weak type, yet still refrain.</p>\n\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/rafah_gaza_war/\">#</a></h2>\n<script>\n\nfunction toggleInteraction() {\n    var code = document.getElementById(\"code\");\n    var button = document.getElementById(\"toggle-button\");\n    code.classList.toggle('active');\n\n    var isVisible = code.classList.contains('active');\n    var buttonText = isVisible ? 'Hide' : 'Explore Scenarios';\n    button.textContent = buttonText\n}\n\nconst calculateMinProb = () => {\n    const k = parseFloat(document.getElementById(\"k\").value);\n    const rn = parseFloat(document.getElementById(\"rn\").value);\n    const theta =  k / (k + rn);\n    document.getElementById(\"theta\").textContent = parseFloat(theta.toFixed(4))\n}\n</script><hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>Formally if you take first derivatives you can see that the expression is increasing in <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.011ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 889 683\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></mjx-assistive-mml></mjx-container> and decreasing in <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.048ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.726ex\" height=\"1.593ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 1647 704\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(759,0)\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>R</mi><mi>N</mi></math></mjx-assistive-mml></mjx-container>. As both of the second derivatives are negative, as <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.011ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 889 683\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></mjx-assistive-mml></mjx-container> gets larger <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Œ∏</mi></math></mjx-assistive-mml></mjx-container> approaches 1; and as <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.048ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.726ex\" height=\"1.593ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 1647 704\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\" style=\"stroke-width: 3;\"></path></g><g data-mml-node=\"mi\" transform=\"translate(759,0)\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>R</mi><mi>N</mi></math></mjx-assistive-mml></mjx-container> gets smaller, <mjx-container class=\"MathJax\" jax=\"SVG\" style=\"direction: ltr; position: relative;\"><svg style=\"overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\" aria-hidden=\"true\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\" style=\"stroke-width: 3;\"></path></g></g></g></svg><mjx-assistive-mml unselectable=\"on\" display=\"inline\" style=\"top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Œ∏</mi></math></mjx-assistive-mml></mjx-container> approaches 0. <a href=\"https://tristinb.github.io/blog/rafah_gaza_war/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2024-05-09T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/polls/",
			"url": "https://tristinb.github.io/blog/polls/",
			"title": "Sources of Polling Error",
			"content_html": "<p>Pollsters and journalists often present polling results as being correct to within a plus or minus three percentage points, with 95 percent confidence. However, we often see election results fall outside this three percentage point error. In the 2020 election, for example, polls missed by an average of <a href=\"https://aapor.org/wp-content/uploads/2022/11/Task-Force-on-2020-Pre-Election-Polling_Executive-Summary.pdf\">4.5 percentage points at the national level</a>. This post explores where this additional polling error comes from and how we should interpret polls in light of this additional error. As a quick note, since polls are surveys of respondents' vote preferences, I use the words polls and surveys synonymously.</p>\n<h2 id=\"sampling-error-the-plus-or-minus-3-percent\" tabindex=\"-1\">Sampling Error: The Plus or Minus 3 Percent <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<p>If we assume a three percent margin of error and we see a poll that says 54 percent of the respondents prefer Hans to Franz then we can be 95 percent confident that the true proportion of the population as a whole that prefers Hans lies somewhere between 51 and 57 percent. The &quot;95 percent confident&quot; means that if we ran our poll a million times, we would only see a result less than 51 percent or greater than 57 in only 5 percent of these polls.</p>\n<p>The following bit of python code simulates this process. The code assumes you ask 1,000 people if they prefer Hans or Franz. If they prefer Hans, record a 1. Otherwise, record 0. We assume the true proportion of the population that prefers Hans a is 54 percent. This is one poll. We can now run this 10 thousand times and see how often the polls find support as either less than 51 percent or greater than 57 percent.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\npopulation_pct<span class=\"token operator\">=</span><span class=\"token number\">.54</span> <span class=\"token comment\"># True value of the population</span>\npoll_sample_size <span class=\"token operator\">=</span> <span class=\"token number\">1000</span> <span class=\"token comment\"># poll 1000 people</span>\ntest_draws <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>binomial<span class=\"token punctuation\">(</span>poll_sample_size<span class=\"token punctuation\">,</span> pop_pct<span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token number\">10_000</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span>poll_sample_size <span class=\"token comment\"># sample from a binomial distribution; divide by n since we want a proportion</span></code></pre>\n<p>The plot below compares each of the 10 thousand samples from this distribution to what we would expect in theory. Notice that they are quite similar.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">from</span> scipy <span class=\"token keyword\">import</span> stats\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\nmin_num_vot <span class=\"token operator\">=</span> <span class=\"token number\">450</span>\nmax_num_vote <span class=\"token operator\">=</span> <span class=\"token number\">631</span>\n\nx <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>min_num_vot<span class=\"token punctuation\">,</span> max_num_vote<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\ntheoretical_distribution <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>n<span class=\"token operator\">=</span>poll_sample_size<span class=\"token punctuation\">,</span> p<span class=\"token operator\">=</span>pop_pct<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>pmf<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx_label <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>i<span class=\"token operator\">/</span>poll_sample_size <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> x<span class=\"token punctuation\">]</span> <span class=\"token comment\"># scale for plot, want a proportion, not raw count out of 1000</span>\n\nfig<span class=\"token punctuation\">,</span> ax <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplots<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nhist<span class=\"token punctuation\">,</span> bins<span class=\"token punctuation\">,</span> _ <span class=\"token operator\">=</span> ax<span class=\"token punctuation\">.</span>hist<span class=\"token punctuation\">(</span>test_draws<span class=\"token punctuation\">,</span> density<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Samples'</span><span class=\"token punctuation\">,</span> bins<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># scale pmf to match area in histogram; bin widths are scaled by 1000</span>\nscaled_pmf <span class=\"token operator\">=</span> theoretical_dist<span class=\"token operator\">*</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>hist<span class=\"token operator\">*</span>np<span class=\"token punctuation\">.</span>diff<span class=\"token punctuation\">(</span>bins<span class=\"token punctuation\">)</span><span class=\"token operator\">*</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_label<span class=\"token punctuation\">,</span> scaled_pmf<span class=\"token punctuation\">,</span> linestyle<span class=\"token operator\">=</span><span class=\"token string\">'--'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'True Distribution'</span><span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'Samples vs True Distribution'</span><span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>set_ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Number of Polls'</span><span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nprop_outside_3_pct <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">abs</span><span class=\"token punctuation\">(</span>test_draws<span class=\"token operator\">-</span>population_pct<span class=\"token punctuation\">)</span><span class=\"token operator\">></span><span class=\"token number\">.03</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>test_draws<span class=\"token punctuation\">)</span> <span class=\"token comment\"># how many are outside 3%?</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'Proportion outside 3 percentage points: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>prop_outside_3_pct<span class=\"token punctuation\">:</span><span class=\"token format-spec\"> .2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span></code></pre>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/TZDWyr7ZpS-640.avif 640w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/TZDWyr7ZpS-640.webp 640w\"><img alt=\"Samples drawn from the above distribution\" loading=\"lazy\" decoding=\"async\" class=\"responsive-image\" style=\"max-width: 100%; height: auto;\" src=\"https://tristinb.github.io/img/TZDWyr7ZpS-640.png\" width=\"640\" height=\"480\"></picture></p>\n<pre class=\"language-text\" tabindex=\"0\"><code class=\"language-text\">Proportion outside 3 percentage points:  0.057</code></pre>\n<p>The output shows that close to five percent of the estimates fell outside of plus or minus three percentage points of 54 percent, or about 95 percent were between 51 and 57 percent support for Hans. We see 5.7 percent, rather than 5 percent, of the estimate fell outside of 3 percent because the estimate's standard error, depends on both the number of people you poll (n) and the true proportion of the population that supports candidate A.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/polls/\" id=\"fnref1\">[1]</a></sup> But a sample size of 1000 generally gets close to 3 percent margins at 95 percent confidence.</p>\n<p>The three percentage point error above occurs because we only take a sample of 1,000 from the population rather than measuring the whole thing. Randomness in who is sampled leads to deviations from the population's true value. However, sources other than sampling error generally cause polls and surveys to be off.</p>\n<h2 id=\"bias-who-answers-pollsters\" tabindex=\"-1\">Bias: Who Answers Pollsters? <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<p>In addition to sampling error, any error in a poll can be decomposed to two factors: bias and variance. Bias is how systematically wrong polls tend to be in a certain direction. For example, when polls all tend to overestimate their support for Franz, they are biased. Variance is the error in excess of the sampling error described above, but is not associated with any particular direction -- it can be either to favorable or too unfavorable to Franz. Typically, tools to reduce bias increase variance and vice-versa, this is the well-known <a href=\"https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff\">bias-variance tradeoff</a>.</p>\n<p>A poll will be biased if one candidate's supporters are systematically less likely to respond to a pollster than their competitor's supporters. Conversely, sometimes a candidate's supporters may over-respond to polls relative to others. For example, they could be particularly excited about their candidate, or be eager to voice their displeasure at a scandal.</p>\n<p>The simulation below shows what happens when one side's supporters are systematically less likely to respond to the pollster. We can then look at a simple method to adjust this bias assuming we have estimates on what group is under-responding.</p>\n<p>For the simulation, assume the population is split in half between two groups: group A and group B. Group A will support Hans with a 44 percent probability, while group B will support Hans with a 64 percent probability. If both groups were equally likely to respond, we would expect to see an average of 54 percent support for Hans. However, let's assume group B will only respond to the pollster with a 25 percent probability; while everybody in group A responds to the pollster. In the simulation below, the pollster just needs to sample 1000 people. The pollster doesn't necessarily know what group each respondent belongs to, even though we will collect the groups in the code.</p>\n<p>The code below simulates one pollster collecting this data.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\">a_vote_prob <span class=\"token operator\">=</span> <span class=\"token number\">.44</span>\nb_vote_prob <span class=\"token operator\">=</span> <span class=\"token number\">.64</span>\nb_response_prob <span class=\"token operator\">=</span> <span class=\"token number\">.25</span>\nresults <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\ngroup <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\npoll_sample_size <span class=\"token operator\">=</span> <span class=\"token number\">1000</span>\ni <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n<span class=\"token keyword\">while</span> i<span class=\"token operator\">&lt;</span>poll_sample_size<span class=\"token punctuation\">:</span>\n    a_vote <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>bernoulli<span class=\"token punctuation\">(</span>a_vote_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    results<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>a_vote<span class=\"token punctuation\">)</span>\n    group<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token string\">'a'</span><span class=\"token punctuation\">)</span>\n    i<span class=\"token operator\">+=</span><span class=\"token number\">1</span>\n    <span class=\"token keyword\">if</span> i<span class=\"token operator\">==</span>poll_sample_size<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">break</span>\n    <span class=\"token keyword\">if</span> stats<span class=\"token punctuation\">.</span>uniform<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">&lt;=</span>b_response_prob<span class=\"token punctuation\">:</span>\n        b_vote <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>bernoulli<span class=\"token punctuation\">(</span>b_vote_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        results<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>b_vote<span class=\"token punctuation\">)</span>\n        group<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token string\">'b'</span><span class=\"token punctuation\">)</span>\n        i<span class=\"token operator\">+=</span><span class=\"token number\">1</span></code></pre>\n<p>The code above only simulates one poll. The following simulates 10 thousand different polls.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\">n_polls <span class=\"token operator\">=</span> <span class=\"token number\">10_000</span>\nnum_b_resps <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>poll_sample_size<span class=\"token operator\">//</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> p<span class=\"token operator\">=</span>b_response_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span>n_polls<span class=\"token punctuation\">)</span> <span class=\"token comment\"># tried to get 500 of each group</span>\n\nnum_a_resps <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>poll_sample_size <span class=\"token operator\">-</span> i <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> num_b_resps<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># Pollster needs 1000 respondents, depends on how many they get from b</span>\na_resps <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>num_a_resps<span class=\"token punctuation\">,</span> a_vote_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> n_polls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># a responses</span>\nb_resps <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>num_b_resps<span class=\"token punctuation\">,</span> b_vote_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> n_polls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># b responses</span>\n\nbiased_total <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>a_resps <span class=\"token operator\">+</span> b_resps<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">/</span>poll_sample_size\n\n<span class=\"token comment\">## Collect weights, will discuss below</span>\na_weight <span class=\"token operator\">=</span> a_prop_population<span class=\"token operator\">/</span><span class=\"token punctuation\">(</span>num_a_resps<span class=\"token operator\">/</span>poll_sample_size<span class=\"token punctuation\">)</span> <span class=\"token comment\"># Numerator is the proportion in the population</span>\nb_weight <span class=\"token operator\">=</span> b_prop_population<span class=\"token operator\">/</span><span class=\"token punctuation\">(</span>num_b_resps<span class=\"token operator\">/</span>poll_sample_size<span class=\"token punctuation\">)</span>\n\nipw_weighted_total <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>a_weight<span class=\"token operator\">*</span>a_resps <span class=\"token operator\">+</span> b_weight<span class=\"token operator\">*</span>b_resps<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">/</span>poll_sample_size</code></pre>\n<p>We can now plot what proportion of the population supports Hans according to each of these 10 thousand polls.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/7BkHuzcDp1-640.avif 640w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/7BkHuzcDp1-640.webp 640w\"><img alt=\"Samples drawn with bias compared to true distribution.\" loading=\"lazy\" decoding=\"async\" class=\"responsive-image\" style=\"max-width: 100%; height: auto;\" src=\"https://tristinb.github.io/img/7BkHuzcDp1-640.png\" width=\"640\" height=\"480\"></picture></p>\n<p>The plot below shows the polls are substantially biased against Hans' support. The average amount of support across all 10 thousand polls is 47 percent, rather than the true level of 54 percent. You can also notice very little overlap between the true distribution and the polls. If we run code to see how many of our samples are within three percent of the true value, we get the following:</p>\n<pre class=\"language-text\" tabindex=\"0\"><code class=\"language-text\">Proportion outside 3 percent:  0.9976</code></pre>\n<p>In other words, only 24 out of the 10 thousand polls were within 3 percentage points of the true value. This would occur despite sampling error alone suggesting that 950 should have fallen within 3 percentage points of the true value. If we assumed a 3 percent margin of error, we could be fairly confident Franz would win.</p>\n<p>From this example, we can see that substantial bias can result when one segment of the population does not respond to the poll and this segment also has different views than those more likely to respond. Fortunately, we can adjust for this bias, at least when we know who is under-responding.</p>\n<h2 id=\"correcting-bias-adding-variance\" tabindex=\"-1\">Correcting Bias, Adding Variance <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<p>The code above also included weights. Let's assume that the pollster knew the true distribution of groups A and B in the population, which we defined as 50/50. Let's also assume that the only factor that impacts how likely someone is to respond to the poll is what group they are in.</p>\n<p>Although many techniques exist to correct for bias when you have group-level characteristics, we can use a simple one here: inverse probability weighting (IPW). Essentially, IPM increases the weight for each response for the group that was under-sampled and decreases the weight for each response in the group that was over-sampled.</p>\n<p>The figure below shows the results we get if we adjust the biased draws above with IPW.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/dIXo2WUPri-640.avif 640w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/dIXo2WUPri-640.webp 640w\"><img alt=\"Biased draws corrected with IPW\" loading=\"lazy\" decoding=\"async\" class=\"responsive-image\" style=\"max-width: 100%; height: auto;\" src=\"https://tristinb.github.io/img/dIXo2WUPri-640.png\" width=\"640\" height=\"480\"></picture></p>\n<p>Although this distribution is centered close to the true value of 54 percent, notice that the samples are &quot;wider&quot; than the theoretical distribution. This means that each poll is noisier than expected. We can run code similar to the above to find what proportion falls outside +/- 3 percentage point from the correct value of .54:</p>\n<pre class=\"language-text\" tabindex=\"0\"><code class=\"language-text\">Proportion outside 3 percent:  0.1964</code></pre>\n<p>After this bias correction, we now have nearly 20 percent of each pall falling outside of +/- 3 percentage point from the true value -- substantially more than the five percent we would expect from sampling error alone.</p>\n<p>Unfortunately, pollster's efforts to adjust for bias often results in more variance. Because you may add substantial weight to a small number of respondents, the makeup of these particular respondents can cause poll results to fluctuate wildly. A notable example occured in 2016, when <a href=\"https://www.nytimes.com/2016/10/13/upshot/how-one-19-year-old-illinois-man-is-distorting-national-polling-averages.html\">one person was weighted around 30 times as much as the average respondent</a>. When this person was out of the sample Clinton led; when he was included Clinton trailed. This poll wasn't necessarily systematically pro or anti Clinton, but the inclusion of this one additional respondent made the poll's expected level of Clinton support to vary far beyond what sampling error alone would have us believe.</p>\n<h2 id=\"how-does-this-impact-professional-polls\" tabindex=\"-1\">How Does This Impact Professional Polls? <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<p>A 2018 paper by Shirani-Mehr and coauthors <sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/polls/\" id=\"fnref2\">[2]</a></sup> analyzed US gubernatorial, senatorial, and presidential election polls in the final three weeks of the campaign between 1998 and 2014 with the goal of disentangling the amount of bias and variance in the polls. They find that, on average, bias is about 2 percentage points. This bias isn't systematically for or against either party but fluctuates at random -- if there was a correlation with political party, it could be adjusted for.</p>\n<p>Additionally, the paper finds that variance is about 1.5 percentage points more than we would expect from sampling error alone. The authors speculate this is due to the methods pollsters use to account for bias. Taken together, the additional bias and variance suggests that rather than assuming polls are accurate to within +/- 3 percentage points, we should really assume they are accurate to within +/- 6 to 7 percentage points. This spread would have covered many of the polls in 2020, the biggest polling miss since 1980, where the average poll was off by <a href=\"https://aapor.org/wp-content/uploads/2022/11/Task-Force-on-2020-Pre-Election-Polling_Executive-Summary.pdf\">5.1 percent at the state level</a>.</p>\n<p>In addition to assuming the margin of error is much larger than 3 percent -- which doesn't even make sense in theory since we know there is more than sampling error leaking into polls -- we should think hard about who decides to respond to a poll when interpreting its results, since polls can fail drastically if biasness isn't accounted for.</p>\n<p>A recent poll following Israel's invasion of Gaza showed a surprisingly large number of Gen-Z respondents believed Hamas' murder of civilians was justified. This poll was taken as protests broke out across the country against Israel's invasion. During the 2020 George Floyd protests, protestors were systematically <a href=\"https://www.pewresearch.org/short-reads/2020/06/24/recent-protest-attendees-are-more-racially-and-ethnically-diverse-younger-than-americans-overall/\">younger than Americans as a whole</a>. If these age trends continued, the protests against Israel likely skewed Gen-Z. Protesting may also fires these activists up for their cause, making them more likely to respond to a pollster. If these protestors are also more likely to agree with more extreme statements -- perhaps just being caught in the moment -- then the amount of support for Hamas' use of violence would be drastically inflated. We can try to look toward other indicators to determine how plausible this explanation is. Or perhaps this poll is solid and more than 50 percent of young people support Hamas' act.</p>\n<!-- ## How Should we Interpret Polls? -->\n<!-- Given the declining response to surveys, many firms have resorted to using panels. Many of them, such as YouGov use a mix of panels and probabilistic sampling through methods such as random digit dialing to get their sample. However, one notable issue with panels is that they have a notoriously high rate of attrition -- people take one or two surveys and then never respond again. But the problem arises when those who choose to stay on panels are systematically different from the population with respect to the questions they are asked. For instance, people who like answering survey questions may also like Biden, but we have no measure of \"affinity for answering surveys\" to adjust for this bias. -->\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>We could calculate the value of N we would need for +/- 3 percent to cover 95 percent when the true value of the population is 0.54 as $$.03=1.96\\sqrt{\\frac{.54(1-.54)}{n}}$$ $$\\sqrt{n} = \\frac{1.96}{.03}\\sqrt{0.2484}$$ $$ n = 1060.28 $$ If we set our sample size in the example above to 1061 we will see the number get closer to 0.05. <a href=\"https://tristinb.github.io/blog/polls/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n<li id=\"fn2\" class=\"footnote-item\"><p>Shirani-Mehr, Houshmand, David Rothschild, Sharad Goel, and Andrew Gelman. &quot;Disentangling bias and variance in election polls.&quot; Journal of the American Statistical Association 113, no. 522 (2018): 607-614. <a href=\"https://tristinb.github.io/blog/polls/\" class=\"footnote-backref\">‚Ü©Ô∏é</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2023-11-08T00:00:00Z"
		}
		
	]
}
