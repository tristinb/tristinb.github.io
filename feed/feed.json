{
	"version": "https://jsonfeed.org/version/1.1",
	"title": "Processing Beliefs",
	"language": "en",
	"home_page_url": "https://tristinb.github.io/",
	"feed_url": "https://tristinb.github.io/feed/feed.json",
	"description": "I am writing about beliefs, bro.",
	"author": {
		"name": "Tristin Beckman",
		"url": "https://tristinb.github.io/about"
	},
	"items": [
		{
			"id": "https://tristinb.github.io/blog/weak_beliefs_polls/do_weak_beliefs_bias_polls/",
			"url": "https://tristinb.github.io/blog/weak_beliefs_polls/do_weak_beliefs_bias_polls/",
			"title": "Strength of Beliefs and Polls",
			"content_html": "<p><a href=\"https://tristinb.github.io/blog/polls/\">The previous post</a> explored how selection bias leads to problems in surveys and opinion polls. It assumed respondents had stable, or fixed, beliefs over whatever issue the pollster asked them. But what would happen to a survey's results if respondents had weaker beliefs, leading them to answer with whatever felt right in the moment? For example, consider a poll that resulted in 50 percent of the population favoring A to B. Does this represent half the population holding firm preferences for A and the other half with strong preferences for B? Or does this represent the full population being indifferent between A or B and basically choosing an option randomly? Would different compositions of the population add further bias or variance to a poll? Or does the composition not matter? The simulations below show that the strength of a belief, weak or strong, does not cause any additional problems to a poll.</p>\n<p>Before delving into the consequences of weak or firm beliefs on polling results, it may help to clarify the definition of belief. David McRaney's <em>How Minds Change</em> looks at how conversations can change people's minds on prominent issues such as gay marriage and abortion. At the beginning of these discussions, interviewers often ask something along the lines of &quot;on a scale of 1 to 100, how supportive are you of X&quot;? Respondents rarely responded with a 1 or 100, instead even those with strong opinions tended to reply with something like &quot;5&quot; or &quot;95&quot; rather than 0 or 100. McRaney finds that although small, the area between 1 and 5 or between 95 and 100 creates some space for persuasion. What this means is that beliefs aren't all or nothing propositions; we don't often 100 percent believe or disbelieve something.</p>\n<p>Because beliefs aren't typically fixed dichotomies, researchers define a belief as a probability distribution over all possible outcomes.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/weak_beliefs_polls/do_weak_beliefs_bias_polls/\" id=\"fnref1\">[1]</a></sup> For example, if someone asks about the shape of the earth, we could exhaust all possible outcomes with {&quot;flat&quot;, &quot;spherical&quot;, &quot;turtles&quot;, &quot;something else&quot;}. Each of us may then put a probability on each response. We could do the same with purely factual questions by asking, for example, what is capital of Brazil: {&quot;Rio de Janeiro&quot;, &quot;Sao Paulo&quot;, &quot;Brasilia&quot;, &quot;Another City&quot;}. Some of us may have strong beliefs and put a probability of 1 on one of those outcomes, but someone with weaker beliefs may put 20 percent chance Rio and 80 percent chance Brasilia. If you asked this person 100 times what the capital of Brazil is, you would expect them to say Brasilia 80 times out of those 100 and Rio the other 20. Although this seems erratic, it is what we would expect by defining beliefs as a probability distribution.</p>\n<p>This way of defining beliefs resolves a puzzle that public opinion researchers have noticed since at least the 1960s: people often change their opinion on issues sporadically. If you ask someone the same question at two different periods, especially on abstract questions such as the role of government in the economy, many give different responses in each period. This occurs despite little aggregate changes, as people shifting their opinion in one direction may be cancelled out by people shifting the other way.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/weak_beliefs_polls/do_weak_beliefs_bias_polls/\" id=\"fnref2\">[2]</a></sup> From this finding, much public opinion research, stemming prominently from Zaller's <em>Nature and Origin of Mass Opinion</em>, argues people's responses can be described as samples from a distribution over answers that they deem plausible.</p>\n<p>But what would happen to a public opinion poll, or survey, if at least some people responded as if they were drawing their answer out of a hat? Would this randomness add any additional bias or noise compared to the case when respondents had much stronger beliefs?</p>\n<p>The simulations below answers this question with three scenarios: 1) the population is split into two groups with fixed beliefs. That is, if you poll somebody they will always respond with the same answer 2) The population is split into two groups with strong beliefs. If you poll somebody they will usually respond with the same answer 3) The population is divided into three, two with strong beliefs and the other with weak beliefs, where the group with weak belief is responding as if they are flipping a marginally biased coin and answering accordingly.</p>\n<p>To make this a bit more concrete, let's imagine in each scenario we are interested in preferences of TikTok vs YouTube. Given a probability over either TikTok and YouTube, we can adjust the composition of each group in each scenario to result in the survey showing 55 percent of the &quot;population&quot; favoring TikTok. In each scenario we will have 1,002 respondents per poll.</p>\n<p>A summary of these scenarios, along with the respondents in each group's probability of choosing either TikTok or YouTube are in the tables below.</p>\n<h3 id=\"scenario-1-always-tiktok-always-youtube\" tabindex=\"-1\">Scenario 1: Always TikTok, Always YouTube <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/weak_beliefs_polls/do_weak_beliefs_bias_polls/\">#</a></h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"></th>\n<th style=\"text-align:center\"><strong>Prob. TikTok</strong></th>\n<th style=\"text-align:center\"><strong>Prob. YouTube</strong></th>\n<th style=\"text-align:center\"><strong>Number Respondents</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>Always TikTok</strong></td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">551</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Always YouTube</strong></td>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">451</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"scenario-2-strong-tiktok-strong-youtube\" tabindex=\"-1\">Scenario 2: Strong TikTok, Strong YouTube <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/weak_beliefs_polls/do_weak_beliefs_bias_polls/\">#</a></h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"></th>\n<th style=\"text-align:center\"><strong>Prob. TikTok</strong></th>\n<th style=\"text-align:center\"><strong>Prob. YouTube</strong></th>\n<th style=\"text-align:center\"><strong>Number Respondents</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>Strong TikTok</strong></td>\n<td style=\"text-align:center\">0.95</td>\n<td style=\"text-align:center\">0.05</td>\n<td style=\"text-align:center\">556</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Strong YouTube</strong></td>\n<td style=\"text-align:center\">0.05</td>\n<td style=\"text-align:center\">0.95</td>\n<td style=\"text-align:center\">446</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"scenario-3-strong-tiktok-strong-youtube-weak-tiktok\" tabindex=\"-1\">Scenario 3: Strong TikTok, Strong YouTube, Weak TikTok <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/weak_beliefs_polls/do_weak_beliefs_bias_polls/\">#</a></h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"></th>\n<th style=\"text-align:center\"><strong>Prob. TikTok</strong></th>\n<th style=\"text-align:center\"><strong>Prob. YouTube</strong></th>\n<th style=\"text-align:center\"><strong>Number Respondents</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>Strong TikTok</strong></td>\n<td style=\"text-align:center\">0.95</td>\n<td style=\"text-align:center\">0.05</td>\n<td style=\"text-align:center\">334</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Strong YouTube</strong></td>\n<td style=\"text-align:center\">0.05</td>\n<td style=\"text-align:center\">0.95</td>\n<td style=\"text-align:center\">334</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Weak TikTok</strong></td>\n<td style=\"text-align:center\">0.65</td>\n<td style=\"text-align:center\">0.35</td>\n<td style=\"text-align:center\">334</td>\n</tr>\n</tbody>\n</table>\n<p>The following code simulates surveys of the populations in each of the three scenarios. The figure below provides the results of the simulations from this code.</p>\n<div id=\"code\">\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">from</span> scipy <span class=\"token keyword\">import</span> stats\n\nstrong_tt_prob <span class=\"token operator\">=</span> <span class=\"token number\">.95</span>\nstrong_yt_prob <span class=\"token operator\">=</span> <span class=\"token number\">.95</span>\nweak_prob <span class=\"token operator\">=</span> <span class=\"token number\">.65</span>\nnum_trials <span class=\"token operator\">=</span> <span class=\"token number\">10_000</span>\nn <span class=\"token operator\">=</span> <span class=\"token number\">1002</span>\n\n<span class=\"token comment\"># Scenario 1</span>\nscen_1_dist <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>p<span class=\"token operator\">=</span><span class=\"token number\">.55</span><span class=\"token punctuation\">,</span>n<span class=\"token operator\">=</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span>num_trials<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span>n\n\n<span class=\"token comment\"># Scenario 2</span>\n<span class=\"token comment\">## Sample from each group based on its population</span>\nscen_2_group_samps <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>multinomial<span class=\"token punctuation\">(</span>n<span class=\"token operator\">=</span>n<span class=\"token punctuation\">,</span> p<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">.556</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token operator\">-</span><span class=\"token number\">.556</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span>num_trials<span class=\"token punctuation\">)</span>\nscen_2_p <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>strong_tt_prob<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token operator\">-</span>strong_yt_prob<span class=\"token punctuation\">]</span>\n<span class=\"token comment\">## Now \"poll\" thse who you sampled above based on their probabilities</span>\nscen_2_dist <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>p<span class=\"token operator\">=</span>scen_2_p<span class=\"token punctuation\">,</span>n<span class=\"token operator\">=</span>scen_2_group_samps<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span>n\n\n<span class=\"token comment\"># Scenario 3</span>\n<span class=\"token comment\">## Sample from each group based on its population</span>\nscen_3_group_samps <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>multinomial<span class=\"token punctuation\">(</span>n<span class=\"token operator\">=</span>n<span class=\"token punctuation\">,</span> p<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">.33</span><span class=\"token punctuation\">,</span><span class=\"token number\">.33</span><span class=\"token punctuation\">,</span><span class=\"token number\">.33</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span>num_trials<span class=\"token punctuation\">)</span>\nscen_3_p <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>strong_tt_prob<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token operator\">-</span>strong_yt_prob<span class=\"token punctuation\">,</span> weak_prob<span class=\"token punctuation\">]</span>\nscen_3_dist <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>p<span class=\"token operator\">=</span>scen_3_p<span class=\"token punctuation\">,</span>n<span class=\"token operator\">=</span>group_samps<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span>n</code></pre>\n</div>\n<p><button id=\"toggle-button\" onclick=\"toggleContent()\">Show Code</button></p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/Vaie-78ugm-640.avif 640w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/Vaie-78ugm-640.webp 640w\"><img alt=\"Samples drawn from the above distribution\" loading=\"lazy\" decoding=\"async\" src=\"https://tristinb.github.io/img/Vaie-78ugm-640.png\" width=\"640\" height=\"480\"></picture></p>\n<p>The figure above shows the simulations are basically identical for every scenario. The mean in each is 55 percent preferring TikTok, as expected. In other words, the composition added no bias to the average response. Furthermore, in all three scenarios we see nearly the exact same spread around the mean. Therefore, the composition had no impact on the poll's variance.</p>\n<p>Taken together, the strength of respondents' beliefs have no noticeable impact on the bias or variance of a poll. Since the composition of the population had no impact on the outcomes, we are unlikely to be able to determine the strength of beliefs from a handful of polls. As the three scenarios above show, there are many different ways for a poll to result in 55 percent of the population claiming that they prefer TikTok to YouTube.</p>\n<p>However, a poll is just a snapshot; the public's underlying beliefs change over time. We may suspect that those with weaker beliefs are more apt to shift their support for one outcome or another than those with stronger beliefs. In scenario 3 above, imagine that YouTube launched a dreamy new feature that diminished the uncertain group's preference for TikTok from 65 percent to 45 percent. This shifts our poll above to show around 48 percent preferring TikTok and 52 percent favoring YouTube. This marks a substantial change driven by the one segment with weak beliefs. In other words, breaking news or other events may appear to impact aggregate survey results simply by shifting the underlying probability distribution of an already uncertain group of respondents.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/weak_beliefs_polls/do_weak_beliefs_bias_polls/\" id=\"fnref3\">[3]</a></sup> Given this group has weaker beliefs, it is not unreasonable to expect further news to lead to shifts back in the other direction.</p>\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/weak_beliefs_polls/do_weak_beliefs_bias_polls/\">#</a></h2>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>Bullock, John G., and Gabriel Lenz. &quot;Partisan bias in surveys.&quot; Annual Review of Political Science 22 (2019): 325-342. <a href=\"https://tristinb.github.io/blog/weak_beliefs_polls/do_weak_beliefs_bias_polls/\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n<li id=\"fn2\" class=\"footnote-item\"><p>Kinder, Donald R., and Nathan P. Kalmoe. Neither liberal nor conservative: Ideological innocence in the American public. University of Chicago Press, 2017. <a href=\"https://tristinb.github.io/blog/weak_beliefs_polls/do_weak_beliefs_bias_polls/\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n<li id=\"fn3\" class=\"footnote-item\"><p>Poll aggregates may also change because news events cause partisans -- or those with stronger beliefs -- to become more eager to answer public opinion polls, see: Gelman, Andrew, Sharad Goel, Douglas Rivers, and David Rothschild. &quot;The mythical swing voter.&quot; Quarterly Journal of Political Science 11, no. 1 (2016): 103-130. <a href=\"https://tristinb.github.io/blog/weak_beliefs_polls/do_weak_beliefs_bias_polls/\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2023-11-19T00:00:00Z"
		}
		,
		{
			"id": "https://tristinb.github.io/blog/polls/",
			"url": "https://tristinb.github.io/blog/polls/",
			"title": "Sources of Polling Error",
			"content_html": "<p>Pollsters and journalists often present polling results as being correct to within a plus or minus three percentage points, with 95 percent confidence. However, we often see election results fall outside this three percentage point error. In the 2020 election, for example, polls missed by an average of <a href=\"https://aapor.org/wp-content/uploads/2022/11/Task-Force-on-2020-Pre-Election-Polling_Executive-Summary.pdf\">4.5 percentage points at the national level</a>. This post explores where this additional polling error comes from and how we should interpret polls in light of this additional error. As a quick note, since polls are surveys of respondents' vote preferences, I use the words polls and surveys synonymously.</p>\n<h2 id=\"sampling-error-the-plus-or-minus-3-percent\" tabindex=\"-1\">Sampling Error: The Plus or Minus 3 Percent <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<p>If we assume a three percent margin of error and we see a poll that says 54 percent of the respondents prefer Hans to Franz then we can be 95 percent confident that the true proportion of the population as a whole that prefers Hans lies somewhere between 51 and 57 percent. The &quot;95 percent confident&quot; means that if we ran our poll a million times, we would only see a result less than 51 percent or greater than 57 in only 5 percent of these polls.</p>\n<p>The following bit of python code simulates this process. The code assumes you ask 1,000 people if they prefer Hans or Franz. If they prefer Hans, record a 1. Otherwise, record 0. We assume the true proportion of the population that prefers Hans a is 54 percent. This is one poll. We can now run this 10 thousand times and see how often the polls find support as either less than 51 percent or greater than 57 percent.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\npopulation_pct<span class=\"token operator\">=</span><span class=\"token number\">.54</span> <span class=\"token comment\"># True value of the population</span>\npoll_sample_size <span class=\"token operator\">=</span> <span class=\"token number\">1000</span> <span class=\"token comment\"># poll 1000 people</span>\ntest_draws <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>binomial<span class=\"token punctuation\">(</span>poll_sample_size<span class=\"token punctuation\">,</span> pop_pct<span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token number\">10_000</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span>poll_sample_size <span class=\"token comment\"># sample from a binomial distribution; divide by n since we want a proportion</span></code></pre>\n<p>The plot below compares each of the 10 thousand samples from this distribution to what we would expect in theory. Notice that they are quite similar.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">from</span> scipy <span class=\"token keyword\">import</span> stats\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\nmin_num_vot <span class=\"token operator\">=</span> <span class=\"token number\">450</span>\nmax_num_vote <span class=\"token operator\">=</span> <span class=\"token number\">631</span>\n\nx <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>min_num_vot<span class=\"token punctuation\">,</span> max_num_vote<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\ntheoretical_distribution <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>n<span class=\"token operator\">=</span>poll_sample_size<span class=\"token punctuation\">,</span> p<span class=\"token operator\">=</span>pop_pct<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>pmf<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx_label <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>i<span class=\"token operator\">/</span>poll_sample_size <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> x<span class=\"token punctuation\">]</span> <span class=\"token comment\"># scale for plot, want a proportion, not raw count out of 1000</span>\n\nfig<span class=\"token punctuation\">,</span> ax <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplots<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nhist<span class=\"token punctuation\">,</span> bins<span class=\"token punctuation\">,</span> _ <span class=\"token operator\">=</span> ax<span class=\"token punctuation\">.</span>hist<span class=\"token punctuation\">(</span>test_draws<span class=\"token punctuation\">,</span> density<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Samples'</span><span class=\"token punctuation\">,</span> bins<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># scale pmf to match area in histogram; bin widths are scaled by 1000</span>\nscaled_pmf <span class=\"token operator\">=</span> theoretical_dist<span class=\"token operator\">*</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>hist<span class=\"token operator\">*</span>np<span class=\"token punctuation\">.</span>diff<span class=\"token punctuation\">(</span>bins<span class=\"token punctuation\">)</span><span class=\"token operator\">*</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_label<span class=\"token punctuation\">,</span> scaled_pmf<span class=\"token punctuation\">,</span> linestyle<span class=\"token operator\">=</span><span class=\"token string\">'--'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'True Distribution'</span><span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'Samples vs True Distribution'</span><span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>set_ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Number of Polls'</span><span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nprop_outside_3_pct <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">abs</span><span class=\"token punctuation\">(</span>test_draws<span class=\"token operator\">-</span>population_pct<span class=\"token punctuation\">)</span><span class=\"token operator\">></span><span class=\"token number\">.03</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>test_draws<span class=\"token punctuation\">)</span> <span class=\"token comment\"># how many are outside 3%?</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'Proportion outside 3 percentage points: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>prop_outside_3_pct<span class=\"token punctuation\">:</span><span class=\"token format-spec\"> .2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span></code></pre>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/TZDWyr7ZpS-640.avif 640w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/TZDWyr7ZpS-640.webp 640w\"><img alt=\"Samples drawn from the above distribution\" loading=\"lazy\" decoding=\"async\" src=\"https://tristinb.github.io/img/TZDWyr7ZpS-640.png\" width=\"640\" height=\"480\"></picture></p>\n<pre class=\"language-text\" tabindex=\"0\"><code class=\"language-text\">Proportion outside 3 percentage points:  0.057</code></pre>\n<p>The output shows that close to five percent of the estimates fell outside of plus or minus three percentage points of 54 percent, or about 95 percent were between 51 and 57 percent support for Hans. We see 5.7 percent, rather than 5 percent, of the estimate fell outside of 3 percent because the estimate's standard error, depends on both the number of people you poll (n) and the true proportion of the population that supports candidate A.<sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/polls/\" id=\"fnref1\">[1]</a></sup> But a sample size of 1000 generally gets close to 3 percent margins at 95 percent confidence.</p>\n<p>The three percentage point error above occurs because we only take a sample of 1,000 from the population rather than measuring the whole thing. Randomness in who is sampled leads to deviations from the population's true value. However, sources other than sampling error generally cause polls and surveys to be off.</p>\n<h2 id=\"bias-who-answers-pollsters\" tabindex=\"-1\">Bias: Who Answers Pollsters? <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<p>In addition to sampling error, any error in a poll can be decomposed to two factors: bias and variance. Bias is how systematically wrong polls tend to be in a certain direction. For example, when polls all tend to overestimate their support for Franz, they are biased. Variance is the error in excess of the sampling error described above, but is not associated with any particular direction -- it can be either to favorable or too unfavorable to Franz. Typically, tools to reduce bias increase variance and vice-versa, this is the well-known <a href=\"https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff\">bias-variance tradeoff</a>.</p>\n<p>A poll will be biased if one candidate's supporters are systematically less likely to respond to a pollster than their competitor's supporters. Conversely, sometimes a candidate's supporters may over-respond to polls relative to others. For example, they could be particularly excited about their candidate, or be eager to voice their displeasure at a scandal.</p>\n<p>The simulation below shows what happens when one side's supporters are systematically less likely to respond to the pollster. We can then look at a simple method to adjust this bias assuming we have estimates on what group is under-responding.</p>\n<p>For the simulation, assume the population is split in half between two groups: group A and group B. Group A will support Hans with a 44 percent probability, while group B will support Hans with a 64 percent probability. If both groups were equally likely to respond, we would expect to see an average of 54 percent support for Hans. However, let's assume group B will only respond to the pollster with a 25 percent probability; while everybody in group A responds to the pollster. In the simulation below, the pollster just needs to sample 1000 people. The pollster doesn't necessarily know what group each respondent belongs to, even though we will collect the groups in the code.</p>\n<p>The code below simulates one pollster collecting this data.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\">a_vote_prob <span class=\"token operator\">=</span> <span class=\"token number\">.44</span>\nb_vote_prob <span class=\"token operator\">=</span> <span class=\"token number\">.64</span>\nb_response_prob <span class=\"token operator\">=</span> <span class=\"token number\">.25</span>\nresults <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\ngroup <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\npoll_sample_size <span class=\"token operator\">=</span> <span class=\"token number\">1000</span>\ni <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n<span class=\"token keyword\">while</span> i<span class=\"token operator\">&lt;</span>poll_sample_size<span class=\"token punctuation\">:</span>\n    a_vote <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>bernoulli<span class=\"token punctuation\">(</span>a_vote_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    results<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>a_vote<span class=\"token punctuation\">)</span>\n    group<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token string\">'a'</span><span class=\"token punctuation\">)</span>\n    i<span class=\"token operator\">+=</span><span class=\"token number\">1</span>\n    <span class=\"token keyword\">if</span> i<span class=\"token operator\">==</span>poll_sample_size<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">break</span>\n    <span class=\"token keyword\">if</span> stats<span class=\"token punctuation\">.</span>uniform<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">&lt;=</span>b_response_prob<span class=\"token punctuation\">:</span>\n        b_vote <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>bernoulli<span class=\"token punctuation\">(</span>b_vote_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        results<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>b_vote<span class=\"token punctuation\">)</span>\n        group<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token string\">'b'</span><span class=\"token punctuation\">)</span>\n        i<span class=\"token operator\">+=</span><span class=\"token number\">1</span></code></pre>\n<p>The code above only simulates one poll. The following simulates 10 thousand different polls.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\">n_polls <span class=\"token operator\">=</span> <span class=\"token number\">10_000</span>\nnum_b_resps <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>poll_sample_size<span class=\"token operator\">//</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> p<span class=\"token operator\">=</span>b_response_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span>n_polls<span class=\"token punctuation\">)</span> <span class=\"token comment\"># tried to get 500 of each group</span>\n\nnum_a_resps <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>poll_sample_size <span class=\"token operator\">-</span> i <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> num_b_resps<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># Pollster needs 1000 respondents, depends on how many they get from b</span>\na_resps <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>num_a_resps<span class=\"token punctuation\">,</span> a_vote_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> n_polls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># a responses</span>\nb_resps <span class=\"token operator\">=</span> stats<span class=\"token punctuation\">.</span>binom<span class=\"token punctuation\">(</span>num_b_resps<span class=\"token punctuation\">,</span> b_vote_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rvs<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> n_polls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># b responses</span>\n\nbiased_total <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>a_resps <span class=\"token operator\">+</span> b_resps<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">/</span>poll_sample_size\n\n<span class=\"token comment\">## Collect weights, will discuss below</span>\na_weight <span class=\"token operator\">=</span> a_prop_population<span class=\"token operator\">/</span><span class=\"token punctuation\">(</span>num_a_resps<span class=\"token operator\">/</span>poll_sample_size<span class=\"token punctuation\">)</span> <span class=\"token comment\"># Numerator is the proportion in the population</span>\nb_weight <span class=\"token operator\">=</span> b_prop_population<span class=\"token operator\">/</span><span class=\"token punctuation\">(</span>num_b_resps<span class=\"token operator\">/</span>poll_sample_size<span class=\"token punctuation\">)</span>\n\nipw_weighted_total <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>a_weight<span class=\"token operator\">*</span>a_resps <span class=\"token operator\">+</span> b_weight<span class=\"token operator\">*</span>b_resps<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">/</span>poll_sample_size</code></pre>\n<p>We can now plot what proportion of the population supports Hans according to each of these 10 thousand polls.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/7BkHuzcDp1-640.avif 640w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/7BkHuzcDp1-640.webp 640w\"><img alt=\"Samples drawn with bias compared to true distribution.\" loading=\"lazy\" decoding=\"async\" src=\"https://tristinb.github.io/img/7BkHuzcDp1-640.png\" width=\"640\" height=\"480\"></picture></p>\n<p>The plot below shows the polls are substantially biased against Hans' support. The average amount of support across all 10 thousand polls is 47 percent, rather than the true level of 54 percent. You can also notice very little overlap between the true distribution and the polls. If we run code to see how many of our samples are within three percent of the true value, we get the following:</p>\n<pre class=\"language-text\" tabindex=\"0\"><code class=\"language-text\">Proportion outside 3 percent:  0.9976</code></pre>\n<p>In other words, only 24 out of the 10 thousand polls were within 3 percentage points of the true value. This would occur despite sampling error alone suggesting that 950 should have fallen within 3 percentage points of the true value. If we assumed a 3 percent margin of error, we could be fairly confident Franz would win.</p>\n<p>From this example, we can see that substantial bias can result when one segment of the population does not respond to the poll and this segment also has different views than those more likely to respond. Fortunately, we can adjust for this bias, at least when we know who is under-responding.</p>\n<h2 id=\"correcting-bias-adding-variance\" tabindex=\"-1\">Correcting Bias, Adding Variance <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<p>The code above also included weights. Let's assume that the pollster knew the true distribution of groups A and B in the population, which we defined as 50/50. Let's also assume that the only factor that impacts how likely someone is to respond to the poll is what group they are in.</p>\n<p>Although many techniques exist to correct for bias when you have group-level characteristics, we can use a simple one here: inverse probability weighting (IPW). Essentially, IPM increases the weight for each response for the group that was under-sampled and decreases the weight for each response in the group that was over-sampled.</p>\n<p>The figure below shows the results we get if we adjust the biased draws above with IPW.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://tristinb.github.io/img/dIXo2WUPri-640.avif 640w\"><source type=\"image/webp\" srcset=\"https://tristinb.github.io/img/dIXo2WUPri-640.webp 640w\"><img alt=\"Biased draws corrected with IPW\" loading=\"lazy\" decoding=\"async\" src=\"https://tristinb.github.io/img/dIXo2WUPri-640.png\" width=\"640\" height=\"480\"></picture></p>\n<p>Although this distribution is centered close to the true value of 54 percent, notice that the samples are &quot;wider&quot; than the theoretical distribution. This means that each poll is noisier than expected. We can run code similar to the above to find what proportion falls outside +/- 3 percentage point from the correct value of .54:</p>\n<pre class=\"language-text\" tabindex=\"0\"><code class=\"language-text\">Proportion outside 3 percent:  0.1964</code></pre>\n<p>After this bias correction, we now have nearly 20 percent of each pall falling outside of +/- 3 percentage point from the true value -- substantially more than the five percent we would expect from sampling error alone.</p>\n<p>Unfortunately, pollster's efforts to adjust for bias often results in more variance. Because you may add substantial weight to a small number of respondents, the makeup of these particular respondents can cause poll results to fluctuate wildly. A notable example occured in 2016, when <a href=\"https://www.nytimes.com/2016/10/13/upshot/how-one-19-year-old-illinois-man-is-distorting-national-polling-averages.html\">one person was weighted around 30 times as much as the average respondent</a>. When this person was out of the sample Clinton led; when he was included Clinton trailed. This poll wasn't necessarily systematically pro or anti Clinton, but the inclusion of this one additional respondent made the poll's expected level of Clinton support to vary far beyond what sampling error alone would have us believe.</p>\n<h2 id=\"how-does-this-impact-professional-polls\" tabindex=\"-1\">How Does This Impact Professional Polls? <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<p>A 2018 paper by Shirani-Mehr and coauthors <sup class=\"footnote-ref\"><a href=\"https://tristinb.github.io/blog/polls/\" id=\"fnref2\">[2]</a></sup> analyzed US gubernatorial, senatorial, and presidential election polls in the final three weeks of the campaign between 1998 and 2014 with the goal of disentangling the amount of bias and variance in the polls. They find that, on average, bias is about 2 percentage points. This bias isn't systematically for or against either party but fluctuates at random -- if there was a correlation with political party, it could be adjusted for.</p>\n<p>Additionally, the paper finds that variance is about 1.5 percentage points more than we would expect from sampling error alone. The authors speculate this is due to the methods pollsters use to account for bias. Taken together, the additional bias and variance suggests that rather than assuming polls are accurate to within +/- 3 percentage points, we should really assume they are accurate to within +/- 6 to 7 percentage points. This spread would have covered many of the polls in 2020, the biggest polling miss since 1980, where the average poll was off by <a href=\"https://aapor.org/wp-content/uploads/2022/11/Task-Force-on-2020-Pre-Election-Polling_Executive-Summary.pdf\">5.1 percent at the state level</a>.</p>\n<p>In addition to assuming the margin of error is much larger than 3 percent -- which doesn't even make sense in theory since we know there is more than sampling error leaking into polls -- we should think hard about who decides to respond to a poll when interpreting its results, since polls can fail drastically if biasness isn't accounted for.</p>\n<p>A recent poll following Israel's invasion of Gaza showed a surprisingly large number of Gen-Z respondents believed Hamas' murder of civilians was justified. This poll was taken as protests broke out across the country against Israel's invasion. During the 2020 George Floyd protests, protestors were systematically <a href=\"https://www.pewresearch.org/short-reads/2020/06/24/recent-protest-attendees-are-more-racially-and-ethnically-diverse-younger-than-americans-overall/\">younger than Americans as a whole</a>. If these age trends continued, the protests against Israel likely skewed Gen-Z. Protesting may also fires these activists up for their cause, making them more likely to respond to a pollster. If these protestors are also more likely to agree with more extreme statements -- perhaps just being caught in the moment -- then the amount of support for Hamas' use of violence would be drastically inflated. We can try to look toward other indicators to determine how plausible this explanation is. Or perhaps this poll is solid and more than 50 percent of young people support Hamas' act.</p>\n<!-- ## How Should we Interpret Polls? -->\n<!-- Given the declining response to surveys, many firms have resorted to using panels. Many of them, such as YouGov use a mix of panels and probabilistic sampling through methods such as random digit dialing to get their sample. However, one notable issue with panels is that they have a notoriously high rate of attrition -- people take one or two surveys and then never respond again. But the problem arises when those who choose to stay on panels are systematically different from the population with respect to the questions they are asked. For instance, people who like answering survey questions may also like Biden, but we have no measure of \"affinity for answering surveys\" to adjust for this bias. -->\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://tristinb.github.io/blog/polls/\">#</a></h2>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>We could calculate the value of N we would need for +/- 3 percent to cover 95 percent when the true value of the population is 0.54 as $$.03=1.96\\sqrt{\\frac{.54(1-.54)}{n}}$$ $$\\sqrt{n} = \\frac{1.96}{.03}\\sqrt{0.2484}$$ $$ n = 1060.28 $$ If we set our sample size in the example above to 1061 we will see the number get closer to 0.05. <a href=\"https://tristinb.github.io/blog/polls/\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n<li id=\"fn2\" class=\"footnote-item\"><p>Shirani-Mehr, Houshmand, David Rothschild, Sharad Goel, and Andrew Gelman. &quot;Disentangling bias and variance in election polls.&quot; Journal of the American Statistical Association 113, no. 522 (2018): 607-614. <a href=\"https://tristinb.github.io/blog/polls/\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n</ol>\n</section>\n",
			"date_published": "2023-11-08T00:00:00Z"
		}
		
	]
}
